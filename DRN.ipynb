{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    from drn import *\n",
    "except ImportError:\n",
    "    print(\"The 'drn' package is not installed. Installing it now...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"git+https://github.com/EricTianDong/drn.git\"])\n",
    "    from drn import *\n",
    "\n",
    "print(\"The 'drn' package is installed and ready to use.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import scipy\n",
    "from scipy.stats import wilcoxon\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm.auto import trange\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.set_num_threads(1)\n",
    "#from sklearn import set_config\n",
    "#set_config(transform_output=\"pandas\")\n",
    "\n",
    "import skopt\n",
    "import skopt.plots\n",
    "from skopt.space import Integer, Real, Categorical\n",
    "from skopt.plots import plot_convergence, plot_objective, plot_evaluations\n",
    "\n",
    "# sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "plt.rcParams[\"savefig.dpi\"] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust if needed\n",
    "plt.rcParams['xtick.labelsize'] = 15\n",
    "plt.rcParams['ytick.labelsize'] = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The notebook will save files into subdirectories of the current working directory.\n",
    "# Here we make the directories if they do not already exist.\n",
    "directories = [\"plots\", \"models/reg\", \"models/synth\", \"models/real\"]\n",
    "for directory in directories:\n",
    "    Path(directory).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective function to minimise for DRN\n",
    "def objective_drn(params, X_train, Y_train, X_val, Y_val,\n",
    "                  train_dataset, val_dataset, \n",
    "                  kl_direction='forwards', criteria='CRPS', patience=30):\n",
    "    num_hidden_layers, hidden_size, dropout_rate, lr, kl_alpha, mean_alpha, dv_alpha, batch_size, proportion, min_obs = params\n",
    "\n",
    "    # Print out the current parameters line-by-line with the name beforehand\n",
    "    names = \"num_hidden_layers, hidden_size, dropout_rate, lr, kl_alpha, mean_alpha, dv_alpha, batch_size, proportion, min_obs\".split(\", \")\n",
    "    for name, val in zip(names, params):\n",
    "        print(f\"\\tTrying {name} = {val} (type {type(val)}\")\n",
    "\n",
    "    # Since those integer values are numpy.int64, and that breaks some things, manually convert to Python ints\n",
    "    num_hidden_layers = int(num_hidden_layers)\n",
    "    hidden_size = int(hidden_size)\n",
    "    batch_size = int(batch_size)\n",
    "    min_obs = int(min_obs)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda:0\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    cutpoints = drn_cutpoints(c_0 = np.min(Y_train.detach().numpy()) * 1.05 if np.min(Y_train.detach().numpy()) < 0 else 0.0,\n",
    "                              c_K = np.max(Y_train.detach().numpy()) * 1.05,\n",
    "                              p = proportion,\n",
    "                              y = Y_train.detach().numpy(),\n",
    "                              min_obs = min_obs)\n",
    "    torch.manual_seed(23)\n",
    "    drn_model = DRN(num_features = X_train.shape[1], cutpoints = cutpoints, glm = glm,\\\n",
    "                hidden_size=hidden_size, num_hidden_layers=num_hidden_layers, dropout_rate = dropout_rate)\n",
    "    \n",
    "    # Train the model with the provided hyperparameters\n",
    "    try:\n",
    "        torch.manual_seed(23)\n",
    "        train(\n",
    "            model=drn_model,\n",
    "            criterion=lambda pred, y: drn_loss(pred, y, kl_alpha = kl_alpha, mean_alpha = mean_alpha,\n",
    "                                                     tv_alpha = 0, dv_alpha = dv_alpha, kl_direction = kl_direction),\n",
    "            train_dataset=train_dataset,\n",
    "            val_dataset=val_dataset,\n",
    "            batch_size=batch_size,\n",
    "            epochs=2000,\n",
    "            patience=patience,\n",
    "            lr=lr,\n",
    "            print_details=True,\n",
    "            log_interval=30,\n",
    "            device=device\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Training failed: {e}\")\n",
    "        return 1e6  # Return a large number in case of failure\n",
    "\n",
    "    # Calculate validation loss and return it\n",
    "    grid_size = 3000  # Increase this to get more accurate CRPS estimates\n",
    "    grid = torch.linspace(0, np.max(Y_train.detach().numpy()) * 1.1, grid_size).unsqueeze(-1).to(device)\n",
    "\n",
    "    drn_model.eval()\n",
    "    with torch.no_grad():\n",
    "        dists = drn_model.distributions(X_val)\n",
    "        cdfs = dists.cdf(grid)\n",
    "        grid = grid.squeeze()\n",
    "        crps_score = crps(Y_val, grid, cdfs).mean().item()\n",
    "        nll_score = -dists.log_prob(Y_val).mean().item()\n",
    "        nll_score = (nll_score if np.exp(-nll_score) > 0 else 1e10)\n",
    "    \n",
    "    print(f\"CRPS: {crps_score}, NLL: {nll_score}\")\n",
    "\n",
    "    return(crps_score if criteria == 'CRPS' else nll_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective function to minimize for CANN\n",
    "def objective_cann(params, X_train, Y_train, X_val, Y_val, \n",
    "                   train_dataset, val_dataset, distribution,\n",
    "                   patience = 50):\n",
    "    num_hidden_layers, hidden_size, dropout_rate, lr, batch_size = params\n",
    "  \n",
    "    names = \"num_hidden_layers, hidden_size, dropout_rate, lr, batch_size\".split(\", \")\n",
    "    for name, val in zip(names, params):\n",
    "        print(f\"\\tTrying {name} = {val} (type {type(val)}\")\n",
    "\n",
    "    num_hidden_layers = int(num_hidden_layers)\n",
    "    hidden_size = int(hidden_size)\n",
    "    batch_size = int(batch_size)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda:0\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        \n",
    "    torch.manual_seed(23)\n",
    "    cann = CANN(glm, num_hidden_layers=num_hidden_layers, hidden_size=hidden_size, dropout_rate = dropout_rate)\n",
    "\n",
    "    try:\n",
    "        torch.manual_seed(23)\n",
    "        train(\n",
    "            cann,\n",
    "            gaussian_deviance_loss if distribution == \"gaussian\" else gamma_deviance_loss,\n",
    "            train_dataset,\n",
    "            val_dataset,\n",
    "            epochs=2000,\n",
    "            lr=lr,\n",
    "            patience=patience,\n",
    "            batch_size=batch_size,\n",
    "        )\n",
    "        cann.update_dispersion(X_train, Y_train)\n",
    "    except Exception as e:\n",
    "        print(f\"Training failed: {e}\")\n",
    "        return 1e6  \n",
    "\n",
    "    grid_size = 3000 \n",
    "    grid = torch.linspace(0, np.max(Y_train.detach().numpy()) * 1.1, grid_size).unsqueeze(-1).to(device)\n",
    "\n",
    "    cann.eval()\n",
    "    with torch.no_grad():\n",
    "        dists = cann.distributions(X_val)\n",
    "        cdfs = dists.cdf(grid)\n",
    "        grid = grid.squeeze()\n",
    "        crps_score = crps(Y_val, grid, cdfs).mean().item()\n",
    "\n",
    "    return crps_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective function to minimise for MDN\n",
    "def objective_mdn(params, X_train, Y_train, X_val, Y_val,\n",
    "                   train_dataset, val_dataset, distribution,\n",
    "                   patience = 50):\n",
    "    num_hidden_layers, hidden_size, dropout_rate, lr, num_components, batch_size = params\n",
    "  \n",
    "    names = \"num_hidden_layers, hidden_size, dropout_rate, lr, num_components, batch_size\".split(\", \")\n",
    "    for name, val in zip(names, params):\n",
    "        print(f\"\\tTrying {name} = {val} (type {type(val)}\")\n",
    "\n",
    "    num_hidden_layers = int(num_hidden_layers)\n",
    "    hidden_size = int(hidden_size)\n",
    "    batch_size = int(batch_size)\n",
    "    num_components = int(num_components)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda:0\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    torch.manual_seed(23)\n",
    "    mdn = MDN(X_train.shape[1], num_components=num_components, hidden_size=hidden_size,\n",
    "                   num_hidden_layers=num_hidden_layers, dropout_rate = dropout_rate,\\\n",
    "                distribution= distribution)\n",
    "        \n",
    "    try:\n",
    "        torch.manual_seed(23)\n",
    "        train(\n",
    "                mdn,\n",
    "                gaussian_mdn_loss if distribution == \"gaussian\" else gamma_mdn_loss,\n",
    "                train_dataset,\n",
    "                val_dataset,\n",
    "                lr=lr,\n",
    "                batch_size=batch_size,\n",
    "                epochs=2000,\n",
    "                patience=patience,\n",
    "                device = device\n",
    "        )\n",
    "        mdn.eval()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f\"Training failed: {e}\")\n",
    "        return 1e6  \n",
    "\n",
    "    grid_size = 3000  \n",
    "    grid = torch.linspace(0, np.max(Y_train.detach().numpy()) * 1.1, grid_size).unsqueeze(-1).to(device)\n",
    "\n",
    "    mdn.eval()\n",
    "    with torch.no_grad():\n",
    "        dists = mdn.distributions(X_val)\n",
    "        cdfs = dists.cdf(grid)\n",
    "        grid = grid.squeeze()\n",
    "        crps_score = crps(Y_val, grid, cdfs).mean().item()\n",
    "\n",
    "    return crps_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective function to minimise for DDR\n",
    "def objective_ddr(params, X_train, Y_train, X_val, Y_val,\n",
    "                   train_dataset, val_dataset,\n",
    "                   patience = 30):\n",
    "    num_hidden_layers, hidden_size, dropout_rate, lr, proportion, batch_size = params\n",
    "  \n",
    "    names = \"num_hidden_layers, hidden_size, dropout_rate, lr, proportion, batch_size\".split(\", \")\n",
    "    for name, val in zip(names, params):\n",
    "        print(f\"\\tTrying {name} = {val} (type {type(val)}\")\n",
    "\n",
    "    num_hidden_layers = int(num_hidden_layers)\n",
    "    hidden_size = int(hidden_size)\n",
    "    batch_size = int(batch_size)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda:0\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        \n",
    "    cutpoints_DDR = ddr_cutpoints(c_0 = np.min(Y_train.detach().numpy()) * 1.05 if np.min(Y_train.detach().numpy()) < 0 else 0.0,\n",
    "                              c_K = np.max(Y_train.detach().numpy()) * 1.05, \n",
    "                              y = Y_train.detach().numpy(),\n",
    "                              p = proportion)\n",
    "\n",
    "    torch.manual_seed(23)\n",
    "    ddr_model = DDR(X_train.shape[1], cutpoints_DDR , num_hidden_layers=num_hidden_layers,\\\n",
    "               hidden_size=hidden_size, dropout_rate = dropout_rate)\n",
    "\n",
    "    try:\n",
    "        torch.manual_seed(23)\n",
    "        train(\n",
    "            ddr_model,\n",
    "            ddr_loss,\n",
    "            train_dataset,\n",
    "            val_dataset,\n",
    "            epochs=2000,\n",
    "            lr=lr,\n",
    "            patience=patience,\n",
    "            batch_size=batch_size,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Training failed: {e}\")\n",
    "        return 1e6  \n",
    "\n",
    "    grid_size = 3000  \n",
    "    grid = torch.linspace(0, np.max(Y_train.detach().numpy()) * 1.1, grid_size).unsqueeze(-1).to(device)\n",
    "\n",
    "    ddr_model.eval()\n",
    "    with torch.no_grad():\n",
    "        dists = ddr_model.distributions(X_val)\n",
    "        cdfs = dists.cdf(grid)\n",
    "        grid = grid.squeeze()\n",
    "        crps_score = crps(Y_val, grid, cdfs).mean().item()\n",
    "\n",
    "    return crps_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantile Residuals and Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_residuals(y, F_, interval):\n",
    "    if y < interval[0]:\n",
    "        return 0\n",
    "    if y > interval[len(interval) - 1]:\n",
    "        return 1\n",
    "    for i in range(len(interval) - 1):\n",
    "        if y > interval[i] and y <= interval[i + 1]:\n",
    "            idx_low = i\n",
    "            idx_up = i + 1\n",
    "            return 0.5 * (F_[idx_low] + F_[idx_up])\n",
    "\n",
    "def quantile_points(cdfs, response, grid):\n",
    "    response = np.array(response)\n",
    "    GLM_points = [[0]] * len(response)\n",
    "    CANN_points = [[0]] * len(response)\n",
    "    MDN_points = [[0]] * len(response)\n",
    "    DDR_points = [[0]] * len(response)\n",
    "    DRN_points = [[0]] * len(response)\n",
    "\n",
    "    for k in trange(len(response)):\n",
    "        # GLM\n",
    "        GLM_points[k] = quantile_residuals(response[k], cdfs[\"GLM\"][:, k].detach().numpy(), grid.detach().numpy())\n",
    "\n",
    "        # CANN\n",
    "        CANN_points[k] = quantile_residuals(response[k], cdfs[\"CANN\"][:, k].detach().numpy(), grid.detach().numpy())\n",
    "\n",
    "        # MDN\n",
    "        MDN_points[k] = quantile_residuals(response[k], cdfs[\"MDN\"][:, k].detach().numpy(), grid.detach().numpy())\n",
    "\n",
    "        # DDR\n",
    "        DDR_points[k] = quantile_residuals(response[k], cdfs[\"DDR\"][:, k].detach().numpy(), grid.detach().numpy())\n",
    "\n",
    "        # DRN\n",
    "        DRN_points[k] = quantile_residuals(response[k], cdfs[\"DRN\"][:, k].detach().numpy(), grid.detach().numpy())\n",
    "\n",
    "    return(GLM_points, MDN_points, DDR_points, DRN_points, CANN_points)\n",
    "\n",
    "def quantile_residuals_plots(model_points):\n",
    "    quantiles = [0] * len(model_points)\n",
    "    for i in range(len(model_points)):\n",
    "        quantiles[i] = np.array(scipy.stats.norm.ppf(model_points[i]))\n",
    "\n",
    "    figure, axes = plt.subplots(2, 2, figsize=(26, 26))\n",
    "    sm.qqplot(quantiles[0], line=\"45\", ax=axes[0, 0])\n",
    "    sm.qqplot(quantiles[1], line=\"45\", ax=axes[0, 1])\n",
    "    sm.qqplot(quantiles[2], line=\"45\", ax=axes[1, 0])\n",
    "    sm.qqplot(quantiles[3], line=\"45\", ax=axes[1, 1])\n",
    "    # sm.qqplot(quantiles[4], line=\"45\", ax=axes[2, 0])\n",
    "    axes[0, 0].set_title(\"GLM\", fontsize=45, color=\"black\")\n",
    "    axes[0, 0].set_ylim(-4, 4)\n",
    "    axes[0, 0].set_xlim(-3.2, 3.2)\n",
    "    axes[0, 1].set_title(\"MDN\", fontsize=45, color=\"black\")\n",
    "    axes[0, 1].set_ylim(-4, 4)\n",
    "    axes[0, 1].set_xlim(-3.2, 3.2)\n",
    "    axes[1, 0].set_title(\"DDR\", fontsize=45, color=\"black\")\n",
    "    axes[1, 0].set_ylim(-4, 4)\n",
    "    axes[1, 0].set_xlim(-3.2, 3.2)\n",
    "    axes[1, 1].set_title(\"DRN\", fontsize=45, color=\"black\")\n",
    "    axes[1, 1].set_ylim(-4, 4)\n",
    "    axes[1, 1].set_xlim(-3.2, 3.2)\n",
    "    \n",
    "    # Set font size for all axes labels and tick labels\n",
    "    for ax in axes.flat:\n",
    "        # Set the font size of axis labels\n",
    "        ax.set_xlabel('Theoretical Quantiles', fontsize=45)  # Adjust fontsize as needed\n",
    "        ax.set_ylabel('Sample Quantiles', fontsize=45)  # Adjust fontsize as needed\n",
    "        \n",
    "        # Set the font size of tick labels\n",
    "        ax.tick_params(axis='both', which='major', labelsize=40)  # Adjust labelsize as needed\n",
    "\n",
    "    figure.suptitle(\"Quantile Residuals\", fontsize=60, y=0.99) #fontweight=\"bold\"\n",
    "    plt.tight_layout(pad=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the index (from the list lst_new) that gives the closest value to the given scalar y\n",
    "def closest_index(y, lst_new):\n",
    "    low, high = 0, len(lst_new) - 1\n",
    "    while low < high - 1:\n",
    "        mid = (low + high) // 2\n",
    "        if lst_new[mid] == y:\n",
    "            return mid\n",
    "        elif lst_new[mid] < y:\n",
    "            low = mid\n",
    "        else:\n",
    "            high = mid\n",
    "\n",
    "    if abs(lst_new[low] - y) <= abs(lst_new[high] - y):\n",
    "        return low\n",
    "    else:\n",
    "        return high\n",
    "\n",
    "def calibration_plot_stats(cdfs_, grid, responses):\n",
    "    Q_predicted = [[0]] * len(responses)\n",
    "    Q_empirical = [[0]] * len(responses)\n",
    "\n",
    "    cdfs_ = cdfs_.T\n",
    "\n",
    "    for k in trange(len(responses)):\n",
    "        y = responses[k]\n",
    "        Q_predicted[k] = np.array(cdfs_[k])[closest_index(y, grid)]\n",
    "        all_quantiles = [\n",
    "            np.array(cdfs_[j])[closest_index(responses[j], grid)] <= Q_predicted[k]\n",
    "            for j in range(len(responses))\n",
    "        ]\n",
    "        Q_empirical[k] = np.sum(all_quantiles) / len(responses)\n",
    "\n",
    "    return (Q_predicted, Q_empirical)\n",
    "\n",
    "def calibration_plot(cdfs_, y, grid):\n",
    "    responses = np.array(y)\n",
    "\n",
    "    Q_predicted_GLM, Q_empirical_GLM = calibration_plot_stats(\n",
    "        cdfs_[\"GLM\"].detach().numpy(), grid.detach().numpy(), responses\n",
    "    )\n",
    "    Q_predicted_CANN, Q_empirical_CANN = calibration_plot_stats(\n",
    "        cdfs_[\"CANN\"].detach().numpy(), grid.detach().numpy(), responses\n",
    "    )\n",
    "    Q_predicted_MDN, Q_empirical_MDN = calibration_plot_stats(\n",
    "        cdfs_[\"MDN\"].detach().numpy(), grid.detach().numpy(), responses\n",
    "    )\n",
    "    Q_predicted_DDR, Q_empirical_DDR = calibration_plot_stats(\n",
    "        cdfs_[\"DDR\"].detach().numpy(), grid.detach().numpy(), responses\n",
    "    )\n",
    "    Q_predicted_DRN, Q_empirical_DRN = calibration_plot_stats(\n",
    "        cdfs_[\"DRN\"].detach().numpy(), grid.detach().numpy(), responses\n",
    "    )\n",
    "\n",
    "    GLM_STATS = np.sum((np.array(Q_predicted_GLM) - np.array(Q_empirical_GLM)) ** 2) / len(\n",
    "        responses\n",
    "    )\n",
    "    CANN_STATS = np.sum(\n",
    "        (np.array(Q_predicted_CANN) - np.array(Q_empirical_CANN)) ** 2\n",
    "    ) / len(responses)\n",
    "    MDN_STATS = np.sum((np.array(Q_predicted_MDN) - np.array(Q_empirical_MDN)) ** 2) / len(\n",
    "        responses\n",
    "    )\n",
    "    DDR_STATS = np.sum((np.array(Q_predicted_DDR) - np.array(Q_empirical_DDR)) ** 2) / len(\n",
    "        responses\n",
    "    )\n",
    "    DRN_STATS = np.sum(\n",
    "        (np.array(Q_predicted_DRN) - np.array(Q_empirical_DRN)) ** 2\n",
    "    ) / len(responses)\n",
    "\n",
    "    figure, axes = plt.subplots(1, 1, figsize=(10, 10))\n",
    "\n",
    "    plt.scatter(\n",
    "        Q_predicted_GLM,\n",
    "        Q_empirical_GLM,\n",
    "        s=6,\n",
    "        color=\"gray\",\n",
    "        label=f\"GLM \\n $\\sum_j (p_j-\\hat p_j)^2= {round(GLM_STATS*len(responses), 4)}$\",\n",
    "    )\n",
    "    plt.scatter(\n",
    "        Q_predicted_CANN,\n",
    "        Q_empirical_CANN,\n",
    "        s=6,\n",
    "        color=\"green\",\n",
    "        label=f\"CANN \\n $\\sum_j (p_j-\\hat p_j)^2= {round(CANN_STATS*len(responses), 4)}$\",\n",
    "    )\n",
    "    plt.scatter(\n",
    "        Q_predicted_MDN,\n",
    "        Q_empirical_MDN,\n",
    "        s=6,\n",
    "        color=\"black\",\n",
    "        label=f\"MDN \\n $\\sum_j (p_j-\\hat p_j)^2= {round(MDN_STATS*len(responses), 4)}$\",\n",
    "    )\n",
    "    plt.scatter(\n",
    "        Q_predicted_DDR,\n",
    "        Q_empirical_DDR,\n",
    "        s=6,\n",
    "        label=f\"DDR \\n $\\sum_j (p_j-\\hat p_j)^2= {round(DDR_STATS*len(responses), 4)}$\",\n",
    "    )\n",
    "    plt.scatter(\n",
    "        Q_predicted_DRN,\n",
    "        Q_empirical_DRN,\n",
    "        s=6,\n",
    "        color=\"red\",\n",
    "        label=f\"DRN  \\n $\\sum_j (p_j- p_j)^2={round(DRN_STATS*len(responses), 4)}$\",\n",
    "    )\n",
    "    plt.plot([0, 1], [0, 1], ls=\"--\", color=\"red\")\n",
    "    plt.xlabel(\"Predicted: $\\hat{p}$\", fontsize=30)\n",
    "    plt.ylabel(\"Empirical: $p$\", fontsize=30)\n",
    "    plt.title(\"Calibration Plot\", fontsize=30)\n",
    "    legend = plt.legend(prop={\"size\": 15}, scatterpoints=1)  # Increase scatterpoints for larger marker\n",
    "    for handle in legend.legend_handles:\n",
    "        handle.set_sizes([40]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wilcoxon Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_wilcoxon_test(glm_metrics, cann_metrics, mdn_metrics, ddr_metrics, drn_metrics):\n",
    "    # Perform the Wilcoxon Signed-Rank Test\n",
    "    stat, p_value = wilcoxon(drn_metrics, glm_metrics, alternative='less')\n",
    "    print(\"DRN < GLM\")\n",
    "    print(\"Wilcoxon Signed-Rank Test statistic:\", stat)\n",
    "    print(\"P-value:\", p_value)\n",
    "\n",
    "    stat, p_value = wilcoxon(drn_metrics, cann_metrics, alternative='less')\n",
    "    print(\"DRN < CANN\")\n",
    "    print(\"Wilcoxon Signed-Rank Test statistic:\", stat)\n",
    "    print(\"P-value:\", p_value)\n",
    "\n",
    "    stat, p_value = wilcoxon(drn_metrics, mdn_metrics, alternative='less')\n",
    "    print(\"DRN < MDN\")\n",
    "    print(\"Wilcoxon Signed-Rank Test statistic:\", stat)\n",
    "    print(\"P-value:\", p_value)\n",
    "\n",
    "    stat, p_value = wilcoxon(drn_metrics, ddr_metrics, alternative='less')\n",
    "    print(\"DRN < DDR\")\n",
    "    print(\"Wilcoxon Signed-Rank Test statistic:\", stat)\n",
    "    print(\"P-value:\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll_wilcoxon_test(dists, Y_target, dataset = 'Test'):\n",
    "    # NLL data \n",
    "    nll_model_glm = -dists['GLM'].log_prob(Y_target).squeeze().detach().numpy() \n",
    "    nll_model_cann = -dists['CANN'].log_prob(Y_target).squeeze().detach().numpy() \n",
    "    nll_model_mdn = -dists['MDN'].log_prob(Y_target).squeeze().detach().numpy() \n",
    "    nll_model_ddr = -dists['DDR'].log_prob(Y_target).squeeze().detach().numpy() \n",
    "    nll_model_drn = -dists['DRN'].log_prob(Y_target).squeeze().detach().numpy() \n",
    "\n",
    "    print(\"--------------------------------------------\")\n",
    "    print(f\"{dataset} Data\")\n",
    "    print(\"--------------------------------------------\")\n",
    "\n",
    "    print_wilcoxon_test(nll_model_glm, nll_model_cann, nll_model_mdn, nll_model_ddr, nll_model_drn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crps_wilcoxon_test(cdfs_, Y_target, grid, dataset = 'Test'):\n",
    "    # CRPS data \n",
    "    crps_model_drn =  crps(Y_target, grid, cdfs_['DRN']).squeeze().detach().numpy() \n",
    "    crps_model_glm =  crps(Y_target, grid, cdfs_['GLM']).squeeze().detach().numpy() \n",
    "    crps_model_cann =  crps(Y_target, grid, cdfs_['CANN']).squeeze().detach().numpy() \n",
    "    crps_model_mdn =  crps(Y_target, grid, cdfs_['MDN']).squeeze().detach().numpy() \n",
    "    crps_model_ddr =  crps(Y_target, grid, cdfs_['DDR']).squeeze().detach().numpy() \n",
    "\n",
    "    print(\"--------------------------------------------\")\n",
    "    print(f\"{dataset} Data\")\n",
    "    print(\"--------------------------------------------\")\n",
    "\n",
    "    print_wilcoxon_test(crps_model_glm, crps_model_cann, crps_model_mdn, crps_model_ddr, crps_model_drn)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_wilcoxon_test(dists_, Y_target, dataset = 'Test'):\n",
    "    # MSE data \n",
    "    se_drn =  (dists_['DRN'].mean.squeeze().detach().numpy() - Y_target.squeeze().detach().numpy())**2\n",
    "    se_glm =  (dists_['GLM'].mean.squeeze().detach().numpy() - Y_target.squeeze().detach().numpy())**2\n",
    "    se_cann =  (dists_['CANN'].mean.squeeze().detach().numpy() - Y_target.squeeze().detach().numpy())**2\n",
    "    se_mdn =  (dists_['MDN'].mean.squeeze().detach().numpy() - Y_target.squeeze().detach().numpy())**2\n",
    "    se_ddr =  (dists_['DDR'].mean.squeeze().detach().numpy() - Y_target.squeeze().detach().numpy())**2\n",
    "\n",
    "    print(\"--------------------------------------------\")\n",
    "    print(f\"{dataset} Data\")\n",
    "    print(\"--------------------------------------------\")\n",
    "\n",
    "    print_wilcoxon_test(se_glm, se_cann, se_mdn, se_ddr, se_drn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def quantile_score_raw(y_true, y_pred, p):\n",
    "    \"\"\"\n",
    "    Compute the quantile score for predictions at a specific quantile.\n",
    "\n",
    "    :param y_true: Actual target values as a Pandas Series or PyTorch tensor.\n",
    "    :param y_pred: Predicted target values as a numpy array or PyTorch tensor.\n",
    "    :param p: The cumulative probability as a float\n",
    "    :return: The quantile score as a PyTorch tensor.\n",
    "    \"\"\"\n",
    "    # Ensure that y_true and y_pred are PyTorch tensors\n",
    "    y_true = (\n",
    "        torch.Tensor(y_true.values) if not isinstance(y_true, torch.Tensor) else y_true\n",
    "    )\n",
    "    y_pred = torch.Tensor(y_pred) if not isinstance(y_pred, torch.Tensor) else y_pred\n",
    "    # Reshape y_pred to match y_true if necessary and compute the error\n",
    "    e = y_true - y_pred.reshape(y_true.shape)\n",
    "    # Compute the quantile score\n",
    "    return torch.where(y_true >= y_pred, p * e, (1 - p) * -e)\n",
    "\n",
    "\n",
    "def quantile_losses_raw(\n",
    "    p,\n",
    "    model,\n",
    "    model_name,\n",
    "    X,\n",
    "    y,\n",
    "    max_iter=1000,\n",
    "    tolerance=5e-5,\n",
    "    l=None,\n",
    "    u=None,\n",
    "    print_score=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculate and optionally print the quantile loss for the given data and model.\n",
    "\n",
    "    :param p: The cumulative probability ntile as a float\n",
    "    :param model: The trained model.\n",
    "    :param model_name: The name of the trained model.\n",
    "    :param X: Input features as a Pandas DataFrame or numpy array.\n",
    "    :param y: True target values as a Pandas Series or numpy array.\n",
    "    :param max_iter: The maximum number of iterations for the quantile search algorithm.\n",
    "    :param tolerance: The tolerance for convergence of the the quantile search algorithm.\n",
    "    :param l: The lower bound for the quantile search\n",
    "    :param u: The upper bound for the quantile search\n",
    "    :param print_score: A boolean indicating whether to print the score.\n",
    "    :return: The quantile loss as a PyTorch tensor.\n",
    "    \"\"\"\n",
    "    # Predict quantiles based on the model name\n",
    "    if model_name in [\"GLM\", \"MDN\", \"CANN\"]:\n",
    "        predicted_quantiles = model.quantiles(\n",
    "            X, [p * 100], max_iter=max_iter, tolerance=tolerance, l=l, u=u\n",
    "        )\n",
    "    elif model_name in [\"DDR\", \"DRN\"]:\n",
    "        predicted_quantiles = model.distributions(X).quantiles(\n",
    "            [p * 100], max_iter=max_iter, tolerance=tolerance, l=l, u=u\n",
    "        )\n",
    "\n",
    "    # Compute the quantile score\n",
    "    score = quantile_score_raw(y, predicted_quantiles, p)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ql90_wilcoxon_test(X_features, Y_target, dataset = 'Test'):\n",
    "    # 90% QL data \n",
    "    ql_glm =  quantile_losses_raw(0.9, glm, 'GLM', X_features, Y_target,\n",
    "                                        max_iter = 1000, tolerance = 1e-4,\\\n",
    "                                        l = torch.Tensor([0]),\\\n",
    "                                        u = torch.Tensor([np.max(y_train)+3*(np.max(y_train)-np.min(y_train))])).squeeze().detach().numpy()\n",
    "    ql_glm =  quantile_losses_raw(0.9, glm, 'CANN', X_features, Y_target,\n",
    "                                        max_iter = 1000, tolerance = 1e-4,\\\n",
    "                                        l = torch.Tensor([0]),\\\n",
    "                                        u = torch.Tensor([np.max(y_train)+3*(np.max(y_train)-np.min(y_train))])).squeeze().detach().numpy()\n",
    "    ql_mdn =  quantile_losses_raw(0.9, mdn, 'MDN', X_features, Y_target,\n",
    "                                        max_iter = 1000, tolerance = 1e-4,\\\n",
    "                                        l = torch.Tensor([0]),\\\n",
    "                                        u = torch.Tensor([np.max(y_train)+3*(np.max(y_train)-np.min(y_train))])).squeeze().detach().numpy()\n",
    "    ql_ddr =  quantile_losses_raw(0.9, ddr, 'DDR', X_features, Y_target,\n",
    "                                        max_iter = 1000, tolerance = 1e-4,\\\n",
    "                                        l = torch.Tensor([0]),\\\n",
    "                                        u = torch.Tensor([np.max(y_train)+3*(np.max(y_train)-np.min(y_train))])).squeeze().detach().numpy()\n",
    "    ql_drn =  quantile_losses_raw(0.9, drn, 'DRN', X_features, Y_target,\n",
    "                                        max_iter = 1000, tolerance = 1e-4,\\\n",
    "                                        l = torch.Tensor([0]),\\\n",
    "                                        u = torch.Tensor([np.max(y_train)+3*(np.max(y_train)-np.min(y_train))])).squeeze().detach().numpy()\n",
    "\n",
    "    print(\"--------------------------------------------\")\n",
    "    print(f\"{dataset} Data\")\n",
    "    print(\"--------------------------------------------\")\n",
    "\n",
    "    print_wilcoxon_test(ql_glm, ql_glm, ql_mdn, ql_ddr, ql_drn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4: Regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_gaussian(n=1000, seed=1, specific_instance = None):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    # Parameters\n",
    "    mu = [0, 0]  # means\n",
    "    sigma = [0.5, 0.5]  # standard deviations\n",
    "    rho = 0.0  # correlation coefficient\n",
    "\n",
    "    # Covariance matrix\n",
    "    covariance = [\n",
    "        [sigma[0] ** 2, rho * sigma[0] * sigma[1]],\n",
    "        [rho * sigma[0] * sigma[1], sigma[1] ** 2],\n",
    "    ]\n",
    "\n",
    "    # Generate bivariate normal distribution\n",
    "    x = rng.multivariate_normal(mu, covariance, n)\n",
    "\n",
    "    # Create a non-linear and non-stationary relationship between X_1, X_2 and Y\n",
    "    means = (- x[:, 0] +  x[:, 1]) #+ 0.2 * x[:, 1]**2\n",
    "    dispersion = 0.5 * (x[:, 0] ** 2 + x[:, 1] ** 2) \n",
    "\n",
    "    if specific_instance is not None:\n",
    "        x_1 = specific_instance[0]\n",
    "        x_2 = specific_instance[1]\n",
    "        means = (- x_1 + x_2).repeat(n)\n",
    "        dispersion = (0.5 * (x_1**2 + x_2**2)).repeat(n)\n",
    "\n",
    "    y_normal = rng.normal(means, dispersion)\n",
    "\n",
    "    # Combine the components    \n",
    "    y = (y_normal) \n",
    "\n",
    "    return pd.DataFrame(x, columns=[\"X_1\", \"X_2\"]), pd.Series(y, name=\"Y\"), means, dispersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, target, means, dispersion = generate_synthetic_gaussian(40000)\n",
    "x_train, x_val, x_test, y_train, y_val, y_test,\\\n",
    "      x_train_raw, x_val_raw, x_test_raw,\\\n",
    "          num_features, cat_features,\\\n",
    "             all_categories, ct =\\\n",
    "                split_and_preprocess(features, target, ['X_1', 'X_2'], [], seed = 0, num_standard = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use lowercase \"x_train\" \"y_train\" for pandas dataframes\n",
    "# and uppercase \"X_train\" \"Y_train\" for tensors.\n",
    "X_train = torch.Tensor(x_train.values)\n",
    "Y_train = torch.Tensor(y_train.values)\n",
    "X_val = torch.Tensor(x_val.values)\n",
    "Y_val = torch.Tensor(y_val.values)\n",
    "X_test = torch.Tensor(x_test.values)\n",
    "Y_test = torch.Tensor(y_test.values)\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train, Y_train)\n",
    "val_dataset = torch.utils.data.TensorDataset(X_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = False \n",
    "distribution = \"gaussian\" # distributional assumption for the GLM, CANN, MDN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\nTraining GLM\\n\")\n",
    "glm = GLM.from_statsmodels(X_train, Y_train, distribution=distribution)\n",
    "torch.save(glm.state_dict(), \"models/reg/glm.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutpoints_DRN = drn_cutpoints(c_0 = np.min(y_train) * 1.05 if np.min(y_train) < 0 else 0.0,\n",
    "                              c_K = np.max(y_train) * 1.05,\n",
    "                              p = 0.01,\n",
    "                              y = y_train,\n",
    "                              min_obs = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) No Regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\nTraining DRN\\n\")\n",
    "torch.manual_seed(23)\n",
    "drn_no_penalty = DRN(num_features = x_train.shape[1], cutpoints = cutpoints_DRN, glm = glm,\n",
    "     hidden_size=100, num_hidden_layers=2, baseline_start = False, dropout_rate = 0.2)\n",
    "if training:\n",
    "    train(\n",
    "        drn_no_penalty,\n",
    "        lambda pred, y : drn_loss(pred, y, kl_alpha = 0,\n",
    "                                                mean_alpha = 0,\n",
    "                                                dv_alpha = 0,\n",
    "                                                tv_alpha = 0),   \n",
    "        train_dataset,\n",
    "        val_dataset, \n",
    "        lr=0.001, #lr = 0.0002\n",
    "        batch_size= 200, #batch_size = 50\n",
    "        log_interval=1,\n",
    "        patience=30,\n",
    "        epochs=1000,\n",
    "    )\n",
    "    drn_no_penalty.eval()\n",
    "    torch.save(drn_no_penalty.state_dict(), \"models/reg/drn_no_penalty.pt\")\n",
    "else:\n",
    "    drn_no_penalty.load_state_dict(torch.load(\"models/reg/drn_no_penalty.pt\"))\n",
    "    drn_no_penalty.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1 = 0.5\n",
    "x_2 = 0.5\n",
    "instance = pd.DataFrame(np.array([x_1, x_2]).reshape(1,2), columns = ['X_1', 'X_2'])\n",
    "\n",
    "true_mean = -x_1 + x_2\n",
    "true_scale = 0.5 * (x_1**2 + x_2**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) Small KL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\nTraining DRN\\n\")\n",
    "torch.manual_seed(23)\n",
    "drn_kl_penalty = DRN(num_features = x_train.shape[1], cutpoints = cutpoints_DRN, glm = glm,\\\n",
    "     hidden_size=128, num_hidden_layers=2, baseline_start = False,  dropout_rate = 0.2)\n",
    "if training:\n",
    "    train(\n",
    "        drn_kl_penalty,\n",
    "        lambda pred, y : drn_loss(pred, y, kl_alpha = 0.001,\n",
    "                                                mean_alpha = 0,  #5e-2\n",
    "                                                dv_alpha = 0, #5e-4\n",
    "                                                tv_alpha = 0),   \n",
    "        train_dataset,\n",
    "        val_dataset, \n",
    "        lr=0.001, #lr = 0.0002\n",
    "        batch_size= 200, #batch_size = 50\n",
    "        log_interval=1,\n",
    "        patience=10,\n",
    "        epochs=1000,\n",
    "    )\n",
    "    drn_kl_penalty.eval()\n",
    "    torch.save(drn_kl_penalty.state_dict(), \"models/reg/drn_kl_penalty.pt\")\n",
    "else:\n",
    "    drn_kl_penalty.load_state_dict(torch.load(\"models/reg/drn_kl_penalty.pt\"))\n",
    "    drn_kl_penalty.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(7, 3.5))\n",
    "\n",
    "# Calculate the PDF with 'true_mean' and 'true_scale' parameters\n",
    "true_y_grid = np.linspace(-1.25, 1.25, 1000)\n",
    "true_densities = scipy.stats.norm.pdf(true_y_grid, loc=true_mean, scale=true_scale)\n",
    "\n",
    "# Create the Explainer class to generate plots\n",
    "drn_no_penalty_exp = DRNExplainer(drn_no_penalty, glm, cutpoints_DRN, x_train_raw, cat_features, all_categories, ct)  \n",
    "drn_no_penalty_exp.plot_adjustment_factors(instance = instance,\\\n",
    "                                           num_interpolations=1_000, \n",
    "                                           plot_adjustments_labels = False,\\\n",
    "                                            axes = ax1,\n",
    "                                            x_range = (-1.25, 1.25),\\\n",
    "                                            y_range = (0, 2),\\\n",
    "                                            plot_title = \"\",\n",
    "                                            plot_y_label = \"$f(y|\\\\boldsymbol{X}=(0.5, 0.5)^{\\\\top})$\", \n",
    "                                            )\n",
    "\n",
    "ax1.plot(true_y_grid, true_densities, color='red', label='True', lw=2, zorder=-1)\n",
    "plt.legend()\n",
    "sns.despine()\n",
    "\n",
    "drn_kl_penalty_exp = DRNExplainer(drn_kl_penalty, glm, cutpoints_DRN, x_train_raw, cat_features, all_categories, ct)  \n",
    "drn_kl_penalty_exp.plot_adjustment_factors(instance = instance,\\\n",
    "                                          num_interpolations=1_000, \n",
    "                                          plot_adjustments_labels = False,\\\n",
    "                                          axes = ax2,\n",
    "                                          x_range = (-1.25, 1.25),\\\n",
    "                                          y_range = (0, 2),\\\n",
    "                                            plot_title = \"\",\n",
    "                                           plot_y_label = \"$f(y|\\\\boldsymbol{X}=(0.5, 0.5)^{\\\\top})$\", \n",
    "                                            )\n",
    "\n",
    "ax2.plot(true_y_grid, true_densities, color='red', label='True', lw=2, zorder=-1)\n",
    "plt.legend()\n",
    "sns.despine()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"plots/DRN KL Penalty.png\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c) Excessive Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\nTraining DRN\\n\")\n",
    "torch.manual_seed(23)\n",
    "drn_dv_large_penalty = DRN(num_features = x_train.shape[1], cutpoints = cutpoints_DRN, glm = glm,\\\n",
    "     hidden_size=128, num_hidden_layers=2, baseline_start = True,  dropout_rate = 0.2)\n",
    "if training:\n",
    "    train(\n",
    "        drn_dv_large_penalty,\n",
    "        lambda pred, y : drn_loss(pred, y, kl_alpha = 0, \n",
    "                                            mean_alpha = 0,  \n",
    "                                            dv_alpha = 10, \n",
    "                                            tv_alpha = 0),   \n",
    "        train_dataset,\n",
    "        val_dataset, \n",
    "        lr=0.01, \n",
    "        batch_size= 300,\n",
    "        log_interval=1,\n",
    "        patience=10,\n",
    "        epochs=1000,\n",
    "    )\n",
    "    drn_dv_large_penalty.eval()\n",
    "    torch.save(drn_dv_large_penalty.state_dict(), \"models/reg/drn_dv_large_penalty.pt\")\n",
    "else:\n",
    "    drn_dv_large_penalty.load_state_dict(torch.load(\"models/reg/drn_dv_large_penalty.pt\"))\n",
    "    drn_dv_large_penalty.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (d) Perfect Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\nTraining DRN\\n\")\n",
    "torch.manual_seed(23)\n",
    "drn_everything = DRN(num_features = x_train.shape[1], cutpoints = cutpoints_DRN, glm = glm,\\\n",
    "     hidden_size=128, num_hidden_layers=2, baseline_start = False,  dropout_rate = 0.2)\n",
    "if training:\n",
    "    train(\n",
    "        drn_everything,\n",
    "        lambda pred, y : drn_loss(pred, y, kl_alpha = 1e-3, \n",
    "                                                mean_alpha = 0,  \n",
    "                                                dv_alpha = 5e-4,\n",
    "                                                tv_alpha = 0),   \n",
    "        train_dataset,\n",
    "        val_dataset, \n",
    "        lr=0.001, \n",
    "        batch_size= 100, \n",
    "        log_interval=1,\n",
    "        patience=10,\n",
    "        epochs=1000,\n",
    "    )\n",
    "    drn_everything.eval()\n",
    "    torch.save(drn_everything.state_dict(), \"models/reg/drn_everything.pt\")\n",
    "else:\n",
    "    drn_everything.load_state_dict(torch.load(\"models/reg/drn_everything.pt\"))\n",
    "    drn_everything.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(7, 3.5))\n",
    "\n",
    "# Calculate the PDF with 'true_mean' and 'true_scale' parameters\n",
    "true_y_grid = np.linspace(-1.25, 1.25, 1000)\n",
    "true_densities = scipy.stats.norm.pdf(true_y_grid, loc=true_mean, scale=true_scale)\n",
    "\n",
    "drn_explainer = DRNExplainer(drn_dv_large_penalty, glm, cutpoints_DRN, x_train_raw, cat_features, all_categories, ct)  \n",
    "drn_explainer.plot_adjustment_factors(instance = instance,\\\n",
    "                                      num_interpolations=1_000, \n",
    "                                        plot_adjustments_labels = False,\\\n",
    "                                          axes = ax1,\n",
    "                                          x_range = (-1.25, 1.25),\\\n",
    "                                          y_range = (0, 2),\\\n",
    "                                          plot_title = \"\",\n",
    "                                           plot_y_label = \"$f(y|\\\\boldsymbol{X}=(0.5, 0.5)^{\\\\top})$\", \n",
    "                                            )\n",
    "\n",
    "ax1.plot(true_y_grid, true_densities, color='red', label='True', lw=2, zorder=-1)\n",
    "plt.legend()\n",
    "sns.despine()\n",
    "\n",
    "drn_explainer = DRNExplainer(drn_everything, glm, cutpoints_DRN, x_train_raw, cat_features, all_categories, ct)  \n",
    "drn_explainer.plot_adjustment_factors(instance = instance,\\\n",
    "                                      num_interpolations=1_000, \n",
    "                                        plot_adjustments_labels = False,\\\n",
    "                                          axes = ax2,\n",
    "                                          x_range = (-1.25, 1.25),\\\n",
    "                                          y_range = (0, 2),\\\n",
    "                                            plot_title = \"\",\n",
    "                                           plot_y_label = \"$f(y|\\\\boldsymbol{X}=(0.5, 0.5)^{\\\\top})$\", \n",
    "                                            )\n",
    "\n",
    "ax2.plot(true_y_grid, true_densities, color='red', label='True', lw=2, zorder=-1)\n",
    "plt.legend()\n",
    "sns.despine()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"plots/DRN DV Penalty.png\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 5: Synthetic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sec 5.1: Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_gamma_lognormal(n=1000, seed=1, specific_instance = None):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    # Parameters\n",
    "    mu = [0, 0]  # means\n",
    "    sigma = [0.25, 0.25]  # standard deviations\n",
    "    rho = 0.25  # correlation coefficient\n",
    "\n",
    "    # Covariance matrix\n",
    "    covariance = [\n",
    "        [sigma[0] ** 2, rho * sigma[0] * sigma[1]],\n",
    "        [rho * sigma[0] * sigma[1], sigma[1] ** 2],\n",
    "    ]\n",
    "\n",
    "    # Generate bivariate normal distribution\n",
    "    x = rng.multivariate_normal(mu, covariance, n)\n",
    "\n",
    "    # Create a non-linear and non-stationary relationship between X_1, X_2 and Y\n",
    "    means = np.exp(- x[:, 0] +  x[:, 1]) \n",
    "    dispersion = np.exp(x[:, 0])  / (1 + np.exp((x[:, 0]) * (x[:, 1])))\n",
    "\n",
    "    if specific_instance is not None:\n",
    "        x_1 = specific_instance[0]\n",
    "        x_2 = specific_instance[1]\n",
    "        means = np.exp(- x_1 + x_2).repeat(n)\n",
    "        dispersion = (np.exp(x_1) / (1 + np.exp(x_1 * x_2))).repeat(n)\n",
    "\n",
    "    # Calculate the gamma and lognormal parts of the Y\n",
    "    y_gamma = rng.gamma(1 / dispersion, scale = dispersion * means)\n",
    "    y_lognormal = np.exp(rng.normal(np.log(means), scale = dispersion))\n",
    "    # Combine the components\n",
    "    y = (y_gamma + y_lognormal)\n",
    "\n",
    "    return pd.DataFrame(x, columns=[\"X_1\", \"X_2\"]), pd.Series(y, name=\"Y\"), means, dispersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, target, means, dispersion = generate_synthetic_gamma_lognormal(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, x_test, y_train, y_val, y_test,\\\n",
    "      x_train_raw, x_val_raw, x_test_raw,\\\n",
    "          num_features, cat_features,\\\n",
    "             all_categories, ct =\\\n",
    "                split_and_preprocess(features, target, ['X_1', 'X_2'], [], seed = 42, num_standard = False)\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use lowercase \"x_train\" \"y_train\" for pandas dataframes\n",
    "# and uppercase \"X_train\" \"Y_train\" for tensors.\n",
    "X_train = torch.Tensor(x_train.values)\n",
    "Y_train = torch.Tensor(y_train.values)\n",
    "X_val = torch.Tensor(x_val.values)\n",
    "Y_val = torch.Tensor(y_val.values)\n",
    "X_test = torch.Tensor(x_test.values)\n",
    "Y_test = torch.Tensor(y_test.values)\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train, Y_train)\n",
    "val_dataset = torch.utils.data.TensorDataset(X_val, Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sec 5.2: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = False \n",
    "tuning = False # change it to True if you wish to start hyperpameter tuning\n",
    "shap_run = False # change it to True if you wish to generate SHAP dependence plots \n",
    "distribution = \"gamma\" # distributional assumption for the GLM, CANN, MDN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"\\n\\nTraining GLM\\n\")\n",
    "\n",
    "torch.manual_seed(23)\n",
    "glm = GLM(X_train.shape[1], distribution = distribution)\n",
    "if training:\n",
    "    torch.manual_seed(23)\n",
    "    glm = glm.from_statsmodels(X_train, Y_train, distribution=distribution)\n",
    "    glm.eval()\n",
    "    torch.save(glm.state_dict(), \"models/synth/glm.pt\")\n",
    "else:\n",
    "    torch.manual_seed(23)\n",
    "    glm.load_state_dict(torch.load(\"models/synth/glm.pt\"))\n",
    "    glm.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tuning:\n",
    "    space_cann_synth = [\n",
    "        Integer(1, 4, name='num_hidden_layers'),\n",
    "        Categorical([16, 32, 64, 128, 256, 512], name='hidden_size'),\n",
    "        Real(0.0, 0.5, name='dropout_rate'),\n",
    "        Real(0.0002, 0.01, name='lr'),\n",
    "        Categorical([128, 256, 512], name='batch_size'),\n",
    "    ]\n",
    "\n",
    "    # Run Bayesian optimization\n",
    "    res_cann_synth = skopt.gp_minimize(\n",
    "        lambda params: objective_cann(params, X_train, Y_train, X_val, Y_val, train_dataset, val_dataset, 'gamma'),\n",
    "        space_cann_synth,\n",
    "        n_calls=125,\n",
    "        n_random_starts=25,\n",
    "        random_state=0,\n",
    "        verbose=True\n",
    "    )\n",
    "    best_cann_paras = res_cann_synth.x\n",
    "    print(best_cann_paras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"\\n\\nTraining CANN\\n\")\n",
    "\n",
    "torch.manual_seed(23)\n",
    "\n",
    "# Identical hyperparamters from the paper\n",
    "if not tuning:\n",
    "    # Format: [hidden layers, neurons/layer,\n",
    "    #          dropout rate, learning rate, batch size]\n",
    "    best_cann_paras =[3, 512, 0.0998147335740975, 0.006377183351881593, 256]\n",
    "\n",
    "cann = CANN(glm, num_hidden_layers=int(best_cann_paras[0]), hidden_size=int(best_cann_paras[1]),\n",
    "         dropout_rate = best_cann_paras[2])\n",
    "if training:\n",
    "    torch.manual_seed(23)\n",
    "    train(\n",
    "        cann,\n",
    "        gaussian_deviance_loss if distribution == \"gaussian\" else gamma_deviance_loss,\n",
    "        train_dataset,\n",
    "        val_dataset,\n",
    "        epochs=2000,\n",
    "        lr=best_cann_paras[-2],\n",
    "        patience=50,\n",
    "        batch_size=int(best_cann_paras[-1]),\n",
    "    )\n",
    "    cann.update_dispersion(X_train, Y_train)\n",
    "    cann.eval()\n",
    "    torch.save(cann.state_dict(), \"models/synth/cann.pt\")\n",
    "else:\n",
    "    cann.load_state_dict(torch.load(\"models/synth/cann.pt\"))\n",
    "    cann.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MDN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tuning:\n",
    "    space_mdn_synth = [\n",
    "        Integer(1, 4, name='num_hidden_layers'),\n",
    "        Categorical([16, 32, 64, 128, 256, 512], name='hidden_size'),\n",
    "        Real(0.0, 0.5, name='dropout_rate'),\n",
    "        Real(0.0002, 0.01, name='lr'),\n",
    "        Integer(2, 10, name='num_components'),\n",
    "        Categorical([128, 256, 512], name='batch_size'),\n",
    "    ]\n",
    "\n",
    "    # Run Bayesian optimization\n",
    "    res_mdn_synth = skopt.gp_minimize(\n",
    "        lambda params: objective_mdn(params,\n",
    "                                    X_train,\n",
    "                                    Y_train,\n",
    "                                    X_val, \n",
    "                                    Y_val, \n",
    "                                    train_dataset, \n",
    "                                    val_dataset, \n",
    "                                    'gamma'),\n",
    "        space_mdn_synth,\n",
    "        n_calls=125,\n",
    "        n_random_starts=25,\n",
    "        random_state=0,\n",
    "        verbose=True\n",
    "    )\n",
    "    best_mdn_paras = res_mdn_synth.x\n",
    "    print(best_mdn_paras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"\\n\\nTraining MDN\\n\")\n",
    "\n",
    "# Identical hyperparameters from the paper\n",
    "if not tuning:\n",
    "    # Format: [hidden layers, neurons/layer,\n",
    "    #          dropout rate, learning rate,\n",
    "    #          components, batch size]\n",
    "    best_mdn_paras = [1, 256, 0.5, 0.004506668905856003, 10, 128]\n",
    "\n",
    "torch.manual_seed(23)\n",
    "mdn = MDN(\n",
    "        X_train.shape[1],\n",
    "        num_hidden_layers=int(best_mdn_paras[0]),\n",
    "        hidden_size=int(best_mdn_paras[1]),\n",
    "        dropout_rate = best_mdn_paras[2],\\\n",
    "        num_components=int(best_mdn_paras[-2]),\n",
    "        distribution= distribution)\n",
    "\n",
    "if training:\n",
    "    torch.manual_seed(23)\n",
    "    train(\n",
    "        mdn,\n",
    "        gaussian_mdn_loss if distribution == \"gaussian\" else gamma_mdn_loss,\n",
    "        train_dataset,\n",
    "        val_dataset,\n",
    "        lr=best_mdn_paras[3],\n",
    "        batch_size=int(best_mdn_paras[-1]),\n",
    "        epochs=2000,\n",
    "        patience=50,\n",
    "    )\n",
    "    mdn.eval()\n",
    "    torch.save(mdn.state_dict(), \"models/synth/mdn.pt\")\n",
    "else:\n",
    "    mdn.load_state_dict(torch.load(\"models/synth/mdn.pt\"))\n",
    "    mdn.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tuning:\n",
    "    space_ddr_synth = [\n",
    "        Integer(1, 4, name='num_hidden_layers'),\n",
    "        Categorical([16, 32, 64, 128, 256, 512], name='hidden_size'),\n",
    "        Real(0.0, 0.5, name='dropout_rate'),\n",
    "        Real(0.0002, 0.01, name='lr'),\n",
    "        Categorical(np.linspace(0.01, 0.03, 9), name='proportion'),\n",
    "        Categorical([128, 256, 512], name='batch_size'),\n",
    "    ]\n",
    "\n",
    "    # Run Bayesian optimization\n",
    "    res_ddr_synth = skopt.gp_minimize(\n",
    "        lambda params: objective_ddr(params, X_train, Y_train, X_val, Y_val, train_dataset, val_dataset),\n",
    "        space_ddr_synth,\n",
    "        n_calls=125,\n",
    "        n_random_starts=25,\n",
    "        random_state=0,\n",
    "        verbose=True\n",
    "    )\n",
    "    best_ddr_paras = res_ddr_synth.x\n",
    "    print(best_ddr_paras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"\\n\\nTraining DDR\\n\")\n",
    "\n",
    "# Identical hyperparamters from the paper\n",
    "if not tuning:\n",
    "    # Format: [hidden layers, neurons/layer,\n",
    "    #          dropout rate, learning rate,\n",
    "    #          cutpoints proportion, batch size]\n",
    "    best_ddr_paras = [3, 32, 0.019212713236367366, 0.006415885767981884, 0.03, 256]\n",
    "\n",
    "cutpoints_DDR = ddr_cutpoints(c_0 = np.min(y_train) * 1.05 if np.min(y_train) < 0 else 0.0,\n",
    "                              c_K = np.max(y_train) * 1.05, \n",
    "                              y = y_train,\n",
    "                              p = best_ddr_paras[-2])\n",
    "\n",
    "torch.manual_seed(23)\n",
    "ddr = DDR(x_train.shape[1], cutpoints_DDR , num_hidden_layers=int(best_ddr_paras[0]),\n",
    "                     hidden_size=int(best_ddr_paras[1]), dropout_rate = best_ddr_paras[2])\n",
    "if training:\n",
    "    torch.manual_seed(23)\n",
    "    train(\n",
    "        ddr,\n",
    "        ddr_loss,\n",
    "        train_dataset,\n",
    "        val_dataset, \n",
    "        lr=best_ddr_paras[3],\n",
    "        batch_size=int(best_ddr_paras[-1]),\n",
    "        log_interval=1,\n",
    "        patience=30,\n",
    "        epochs=2000,\n",
    "    )\n",
    "    ddr.eval()\n",
    "    torch.save(ddr.state_dict(), \"models/synth/ddr.pt\")\n",
    "else:\n",
    "    ddr.load_state_dict(torch.load(\"models/synth/ddr.pt\"))\n",
    "    ddr.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DRN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tuning:\n",
    "    space_drn_synth = [\n",
    "        Integer(1, 4, name='num_hidden_layers'),\n",
    "        Categorical([16, 32, 64, 128, 256, 512], name='hidden_size'),\n",
    "        Real(0.0, 0.5, name='dropout_rate'),\n",
    "        Real(0.0002, 0.01, name='lr', prior = 'log-uniform'),\n",
    "        Real(1e-5, 1e-1, name='kl_alpha', prior = 'log-uniform'),\n",
    "        Categorical([1e-5, 1e-4, 1e-3, 1e-2, 1e-1], name='mean_alpha'),\n",
    "        Categorical([1e-3, 1e-2, 1e-1], name='dv_alpha'),\n",
    "        Categorical([128, 256, 512], name='batch_size'),\n",
    "        Categorical(np.linspace(0.02, 0.03, 5), name='proportion'),\n",
    "        Categorical([1, 3, 5], name='min_obs'),\n",
    "    ]\n",
    "\n",
    "    # Run Bayesian optimization\n",
    "    res_drn_synth = skopt.gp_minimize(\n",
    "        lambda params: objective_drn(params, criteria = 'CRPS', \n",
    "                                    X_train=X_train,\n",
    "                                    Y_train=Y_train,\n",
    "                                    X_val=X_val,\n",
    "                                    Y_val=Y_val,\n",
    "                                    train_dataset=train_dataset,\n",
    "                                    val_dataset=val_dataset,\n",
    "                                    kl_direction = 'forwards'),\n",
    "        space_drn_synth,\n",
    "        n_calls=125,\n",
    "        n_random_starts=25,\n",
    "        random_state=0,\n",
    "        verbose=True\n",
    "    )\n",
    "    best_drn_paras = res_drn_synth.x\n",
    "    print(best_drn_paras)\n",
    "\n",
    "    # If we wish,we can generate the following 'correlation' plot,\n",
    "    # loss function values vs. hyperparameters \n",
    "    with plt.rc_context(\n",
    "                    {'xtick.labelsize': 'x-small', \n",
    "                     'ytick.labelsize': 'x-small',\n",
    "                     'axes.labelsize': 'x-small',\n",
    "                     'axes.titlesize': 'x-small'}):\n",
    "        plot_objective(res_drn_synth)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"\\n\\nTraining DRN\\n\")\n",
    "\n",
    "# Identical hyperparamters from the paper\n",
    "if not tuning:\n",
    "  # Format: [hidden layers, neurons/layer,\n",
    "  #          dropout rate, learning rate,\n",
    "  #          kl penalty, mean penalty, roughnesss penalty,\n",
    "  #           batch size, proportion, minimum number of observations]\n",
    "  best_drn_paras = [3, 128,\n",
    "                   0.13984058206702007, 0.0008092281223896455,\n",
    "                   0.0004677145949629566, 0.01, 0.1,\n",
    "                   256, 0.025, 5]\n",
    "\n",
    "cutpoints_DRN = drn_cutpoints(c_0 = np.min(Y_train.detach().numpy()) * 1.05 if np.min(Y_train.detach().numpy()) < 0 else 0.0,\n",
    "                              c_K = np.max(Y_train.detach().numpy()) * 1.05,\n",
    "                              p = best_drn_paras[-2],\n",
    "                              y = Y_train.detach().numpy(),\n",
    "                              min_obs = int(best_drn_paras[-1]))\n",
    "    \n",
    "\n",
    "torch.manual_seed(23)\n",
    "drn = DRN(num_features = X_train.shape[1], cutpoints = cutpoints_DRN, glm = glm,\\\n",
    "                    hidden_size=int(best_drn_paras[1]), num_hidden_layers=int(best_drn_paras[0]),\n",
    "                      baseline_start = False,  dropout_rate = best_drn_paras[2])\n",
    "if training:  \n",
    "    torch.manual_seed(23)\n",
    "    train(\n",
    "                model=drn,\n",
    "                criterion=lambda pred, y: drn_loss(pred, y, kl_alpha = best_drn_paras[4], #2e-4\n",
    "                                                    mean_alpha = best_drn_paras[5],\n",
    "                                                    dv_alpha = best_drn_paras[6],\n",
    "                                                     kl_direction = 'forwards'),   \n",
    "                train_dataset=train_dataset,\n",
    "                val_dataset=val_dataset,\n",
    "                batch_size=int(best_drn_paras[7]),\n",
    "                epochs=2000,\n",
    "                patience=30,\n",
    "                lr=best_drn_paras[3],\n",
    "                print_details=True,\n",
    "                log_interval=1,\n",
    "    )\n",
    "    drn.eval()\n",
    "    torch.save(drn.state_dict(), \"models/synth/drn_tuned.pt\")\n",
    "else:\n",
    "    drn.load_state_dict(torch.load(\"models/synth/drn_tuned.pt\"))\n",
    "    drn.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sec 5.3.1: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"GLM\", \"CANN\", \"MDN\", \"DDR\", \"DRN\"]\n",
    "models = [glm, cann, mdn, ddr, drn]\n",
    "\n",
    "print(\"Generating distributional forecasts\")\n",
    "dists_train = {}\n",
    "dists_val = {}\n",
    "dists_test = {}\n",
    "\n",
    "for name, model in zip(names, models):\n",
    "    print(f\"- {name}\")\n",
    "    dists_train[name] = model.distributions(X_train)\n",
    "    dists_val[name] = model.distributions(X_val)\n",
    "    dists_test[name] = model.distributions(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calculating CDF over a grid\")\n",
    "GRID_SIZE = 3000  # Increase this to get more accurate CRPS estimates\n",
    "grid = torch.linspace(0, np.max(y_train) * 1.1, GRID_SIZE).unsqueeze(-1)\n",
    "\n",
    "cdfs_train = {}\n",
    "cdfs_val = {}\n",
    "cdfs_test = {}\n",
    "\n",
    "for name, model in zip(names, models):\n",
    "    print(f\"- {name}\")\n",
    "    cdfs_train[name] = dists_train[name].cdf(grid)\n",
    "    cdfs_val[name] = dists_val[name].cdf(grid)\n",
    "    cdfs_test[name] = dists_test[name].cdf(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calculating negative loglikelihoods\")\n",
    "nlls_train = {}\n",
    "nlls_val = {}\n",
    "nlls_test = {}\n",
    "\n",
    "for name, model in zip(names, models):\n",
    "    nlls_train[name] = -dists_train[name].log_prob(Y_train).mean()\n",
    "    nlls_val[name] =-dists_val[name].log_prob(Y_val).mean()\n",
    "    nlls_test[name] = -dists_test[name].log_prob(Y_test).mean()\n",
    "\n",
    "for nll_dict, df_name in zip([nlls_train, nlls_val, nlls_test],['training', 'val', 'test']):\n",
    "    print(f'NLL on {df_name} set')\n",
    "    for name, model in zip(names, models):\n",
    "        print(f\"{name}: {nll_dict[name]:.4f}\")\n",
    "    print(f'-------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nll_wilcoxon_test(dists_val, Y_val, 'Validation')\n",
    "nll_wilcoxon_test(dists_test, Y_test, 'Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calculating CRPS\")\n",
    "grid = grid.squeeze()\n",
    "crps_train ={}\n",
    "crps_val = {}\n",
    "crps_test = {}\n",
    "\n",
    "\n",
    "for name, model in zip(names, models):\n",
    "    crps_train[name] = crps(Y_train, grid, cdfs_train[name])\n",
    "    crps_val[name] = crps(Y_val, grid, cdfs_val[name])\n",
    "    crps_test[name] = crps(Y_test, grid, cdfs_test[name])\n",
    "\n",
    "for crps_dict, df_name in zip([crps_train, crps_val, crps_test],['training', 'val', 'test']):\n",
    "    print(f'CRPS on {df_name} set')\n",
    "    for name, model in zip(names, models):\n",
    "        print(f\"{name}: {crps_dict[name].mean():.4f}\")\n",
    "    print(f'------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crps_wilcoxon_test(cdfs_val, Y_val, grid, 'Validation')\n",
    "crps_wilcoxon_test(cdfs_test, Y_test, grid, 'Validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_train = {}\n",
    "rmse_val = {}\n",
    "rmse_test = {}\n",
    "\n",
    "for name, model in zip(names, models):\n",
    "    means_train = dists_train[name].mean\n",
    "    means_val = dists_val[name].mean \n",
    "    means_test = dists_test[name].mean  \n",
    "    rmse_train[name] = rmse(y_train, means_train)\n",
    "    rmse_val[name] = rmse(y_val, means_val)\n",
    "    rmse_test[name] = rmse(y_test, means_test)\n",
    "\n",
    "for rmse_dict, df_name in zip([rmse_train, rmse_val, rmse_test], ['training', 'validation', 'test']):\n",
    "    print(f'RMSE on {df_name} set')\n",
    "    for name, model in zip(names, models):\n",
    "        print(f\"{name}: {rmse_dict[name].mean():.4f}\")\n",
    "    print(f'-------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_wilcoxon_test(dists_val, Y_val, 'Validation')\n",
    "rmse_wilcoxon_test(dists_test, Y_test, 'Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 90 Quantile Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ql_90_train = {}\n",
    "ql_90_val = {}\n",
    "ql_90_test = {}\n",
    "\n",
    "for features, response, dataset_name, ql_dict in zip(\n",
    "                            [X_train, X_val, X_test],\n",
    "                            [y_train, y_val, y_test],\n",
    "                            ['Training', 'Validation', 'Test'],\n",
    "                            [ql_90_train, ql_90_val, ql_90_test]):\n",
    "    print(f'{dataset_name} Dataset Quantile Loss(es)')\n",
    "    for model, model_name in zip(models, names):\n",
    "        ql_dict[model_name] = quantile_losses(\n",
    "                                            0.9,\n",
    "                                            model,\n",
    "                                            model_name,\n",
    "                                            features,\n",
    "                                            response,\n",
    "                                            max_iter = 1000,\n",
    "                                            tolerance = 1e-4,\\\n",
    "                                            l = torch.Tensor([0]),\\\n",
    "                                            u = torch.Tensor([np.max(y_train)+3*(np.max(y_train)-np.min(y_train))])\n",
    "                                            )\n",
    "    print(f\"----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ql90_wilcoxon_test(X_val, Y_val, 'Validation')\n",
    "ql90_wilcoxon_test(X_test, Y_test, 'Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latex_table(nlls_val, crps_val, rmse_val, ql_90_val,\\\n",
    "                         nlls_test, crps_test, rmse_test, ql_90_test,\\\n",
    "                        model_names, label_txt='Evaluation Metrics Table',\\\n",
    "                         caption_txt = 'Evaluation Metrics Table.',\\\n",
    "                           scaling_factor = 1.0):\n",
    "    header_row = (\"\\\\begin{center}\\n\"\n",
    "                +  \"\\captionof{table}{\" + f'{caption_txt}' + '}\\n'\n",
    "                + \"\\label{\" + f'{label_txt}' + '}\\n'\n",
    "                + \"\\scalebox{\" + f'{scaling_factor}' + '}{\\n'\n",
    "                + \"\\\\begin{tabular}{l|cccc|cccc}\\n\\\\toprule\\n\\\\toprule\\n\"\n",
    "                + \"&  \\multicolumn{4}{c}{$\\mathcal{D}_{\\\\text{Validation}}$}\"\n",
    "                + \"& \\multicolumn{4}{c}{ $\\mathcal{D}_{\\\\text{Test}}$}\\\\\\\\ \\n\"\n",
    "                + \" \\cmidrule{2-5}  \\cmidrule{6-9} $\\\\text{Model}$ $\\\\backslash$ $\\\\text{Metrics}$\"\n",
    "                + \" & NLL & CRPS & RMSE & 90\\% QL & NLL & CRPS & RMSE & 90\\% QL \\\\\\\\ \\\\midrule\")\n",
    "    rows = [header_row]\n",
    "\n",
    "    for name in model_names:\n",
    "        row = ( \n",
    "              f\"{name} &  {(nlls_val[name].mean()):.4f}\" \n",
    "              f\" &  {(crps_val[name].mean()):.4f} \"  \n",
    "              f\" & {(rmse_val[name].mean()):.4f} \"  \n",
    "              f\" & {(ql_90_val[name].mean()):.4f} \" \n",
    "              f\" & {(nlls_test[name].mean()):.4f} \"\n",
    "              f\" & {(crps_test[name].mean()):.4f} \" \n",
    "              f\" & {(rmse_test[name].mean()):.4f} \"  \n",
    "              f\" & {(ql_90_test[name].mean()):.4f} \\\\\\\\ \"  \n",
    "              )\n",
    "        rows.append(row)\n",
    "    \n",
    "    table = (\"\\n\".join(rows)  \n",
    "                  + \"\\n\\\\bottomrule\\n\\\\bottomrule\" \n",
    "                  + \"\\n\\\\end{tabular}\"\n",
    "                  +  \"\\n}\"\n",
    "                  + \"\\n\\end{center}\")\n",
    "    return table\n",
    "\n",
    "\n",
    "latex_table = generate_latex_table(nlls_val, crps_val, rmse_val, ql_90_val,\n",
    "                                   nlls_test, crps_test, rmse_test, ql_90_test, names,\n",
    "                                    label_txt='Evaluation Metrics',\n",
    "                                    caption_txt = 'Model comparisons based on various evaluation metrics.',\n",
    "                                    scaling_factor = 0.95 \n",
    "                                    )\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantile Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile_residuals_plots(quantile_points(cdfs_test, y_test, grid))\n",
    "plt.savefig(\"plots/synth/Quantile Residuals Plot Synthetic.png\");\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_plot(cdfs_test, y_test, grid)\n",
    "plt.savefig(\"plots/synth/Calibration Plot Synthetic.png\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sec 5.3.2: Interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigated Instance\n",
    "x_1 = 0.1\n",
    "x_2 = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local: Density Plot and Kernel SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise Explainer\n",
    "drn_explainer = DRNExplainer(drn, glm, cutpoints_DRN, x_train_raw, cat_features, all_categories, ct)\n",
    "\n",
    "# Plot adjustment factors\n",
    "drn_explainer.plot_adjustment_factors(\n",
    "    instance=pd.DataFrame(np.array([x_1, x_2]).reshape(1, 2), columns=['X_1', 'X_2']),\n",
    "    num_interpolations=1000,\n",
    "    plot_adjustments_labels=False,\n",
    "    x_range=(0, 6),\n",
    "    synthetic_data=generate_synthetic_gamma_lognormal,\n",
    ")\n",
    "\n",
    "plt.savefig(\"plots/(0.1, 0.1) Density Plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drn_explainer = DRNExplainer(drn, glm, cutpoints_DRN, x_train_raw, cat_features, all_categories, column_transformer=ct)\n",
    "\n",
    "# Plot DP adjustment SHAP for Mean Adjustment Explanation\n",
    "drn_explainer.plot_dp_adjustment_shap(\n",
    "    instance_raw=pd.DataFrame(np.array([x_1, x_2]).reshape(1, 2), columns=[\"X_1\", \"X_2\"]),\n",
    "    method='Kernel',\n",
    "    nsamples_background_fraction=0.5,\n",
    "    top_K_features=3,\n",
    "    labelling_gap=0.12,\n",
    "    dist_property='Mean',\n",
    "    x_range=(2.14, 2.23),\n",
    "    y_range=(0.0, 0.75),\n",
    "    observation=True,\n",
    "    density_transparency=0.9,\n",
    "    adjustment=True,\n",
    "    shap_fontsize=15,\n",
    "    figsize=(7, 7),\n",
    "    plot_title='Mean Adjustment Explanation',\n",
    "    synthetic_data=generate_synthetic_gamma_lognormal,\n",
    "    legend_loc='upper left',\n",
    ")\n",
    "\n",
    "plt.savefig(\"plots/(0.1, 0.1) Mean Adjustment Plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drn_explainer = DRNExplainer(\n",
    "    drn, glm, cutpoints_DRN, x_train_raw, cat_features, all_categories, column_transformer=ct\n",
    ")\n",
    "\n",
    "drn_explainer.cdf_plot(\n",
    "    instance=pd.DataFrame(\n",
    "        np.array([x_1, x_2]).reshape(1, 2), columns=[\"X_1\", \"X_2\"]\n",
    "    ),\n",
    "    method='Kernel',\n",
    "    nsamples_background_fraction=0.005,\n",
    "    top_K_features=3,\n",
    "    labelling_gap=0.15,\n",
    "    dist_property='90% Quantile',\n",
    "    quantile_bounds = (torch.Tensor([cutpoints_DRN[0]]), torch.Tensor([cutpoints_DRN[-1]*2])),\n",
    "    x_range=(3.4, 3.58),\n",
    "    y_range=(0.87, 0.93),\n",
    "    density_transparency=0.9,\n",
    "    adjustment=True,\n",
    "    shap_fontsize=15,\n",
    "    figsize=(7, 7),\n",
    "    plot_title='90% Quantile Adjustment Explanation',\n",
    "    synthetic_data=generate_synthetic_gamma_lognormal,\n",
    ")\n",
    "\n",
    "plt.savefig(\"plots/(0.1, 0.1) Quantile Adjustment Plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drn_explainer = DRNExplainer(drn, glm, cutpoints_DRN, x_train_raw, cat_features, all_categories, column_transformer=ct)\n",
    "\n",
    "# Plot CDF for 90% Quantile Explanation\n",
    "drn_explainer.cdf_plot(\n",
    "    instance=pd.DataFrame(np.array([x_1, x_2]).reshape(1, 2), columns=[\"X_1\", \"X_2\"]),\n",
    "    method='Kernel',\n",
    "    nsamples_background_fraction=0.05,\n",
    "    top_K_features=3,\n",
    "    labelling_gap=0.16,\n",
    "    dist_property='90% Quantile',\n",
    "    quantile_bounds = (torch.Tensor([cutpoints_DRN[0]]), torch.Tensor([cutpoints_DRN[-1]*2])),\n",
    "    x_range=(0, 8),\n",
    "    y_range=(0., 1.0),\n",
    "    density_transparency=0.9,\n",
    "    adjustment=False,\n",
    "    plot_baseline=False,\n",
    "    synthetic_data=generate_synthetic_gamma_lognormal,\n",
    "    shap_fontsize=15,\n",
    "    figsize=(7, 7),\n",
    "    plot_title='90% Quantile Explanation',\n",
    ")\n",
    "\n",
    "plt.savefig(\"plots/(0.1, 0.1) Quantile Explanation Plot.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global: SHAP Dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise DRNExplainer\n",
    "if shap_run:\n",
    "    drn_explainer = DRNExplainer(\n",
    "        drn, glm, cutpoints_DRN, x_train_raw, cat_features, all_categories, ct\n",
    "    )\n",
    "\n",
    "    # Calculate Kernel SHAP values for the DRN model\n",
    "    kernel_shap_drn = drn_explainer.kernel_shap(\n",
    "        explaining_data=x_test_raw,\n",
    "        distributional_property='Mean', #can change to 'XX% Quantile',\n",
    "        nsamples_background_fraction=0.5,\n",
    "        adjustment=True,\n",
    "        glm_output=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if shap_run:\n",
    "    kernel_shap_drn.global_importance_plot(num_features+cat_features, output = 'drn')\n",
    "    plt.savefig(\"plots/(Synthetic) SHAP Importance Mean.png\");\n",
    "    plt.show()\n",
    "    kernel_shap_drn.beeswarm_plot(num_features+cat_features, output = 'drn')\n",
    "    plt.savefig(\"plots/(Synthetic) SHAP Beeswarm Mean.png\");\n",
    "    plt.show()\n",
    "    kernel_shap_drn.shap_dependence_plot(('X_1', 'X_2'), output = 'drn')\n",
    "    plt.savefig(\"plots/(Synthetic) SHAP Dependence Mean.png\");\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 6: Real Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sec 6.1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "csv_file_path = 'freMPL1.csv'\n",
    "df = pd.read_csv(csv_file_path, on_bad_lines='skip')\n",
    "claims = df.loc[df[\"ClaimAmount\"] > 0, :]\n",
    "\n",
    "claims[\"ClaimAmount\"].plot.density(color=\"green\", xlim=(0, 30000))\n",
    "# Setting the title with a larger font size\n",
    "plt.title('Empirical Density of Truncated Claims', fontsize=20)\n",
    "\n",
    "# Setting the labels for x and y axes with larger font sizes \n",
    "plt.xlabel('Claim Amount ($)', fontsize=15)\n",
    "plt.ylabel('', fontsize=15)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "\n",
    "plt.savefig(\"plots/Empirical Density (Real).png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "target = claims[\"ClaimAmount\"] / 1000\n",
    "features = claims.drop(\"ClaimAmount\", axis=1)\n",
    "features = features.drop(\n",
    "            [\"RecordBeg\", \"RecordEnd\", \"ClaimInd\", \"Garage\"], axis=1\n",
    "        )  # Drop garage due to missing values\n",
    "\n",
    "# Convert \"VehAge\" categories to numeric\n",
    "features[\"VehAge\"] = features[\"VehAge\"].map(\n",
    "            {\n",
    "                \"0\": 0,\n",
    "                \"1\": 1,\n",
    "                \"2\": 2,\n",
    "                \"3\": 3,\n",
    "                \"4\": 4,\n",
    "                \"5\": 5,\n",
    "                \"6-7\": 6,\n",
    "                \"8-9\": 8,\n",
    "                \"10+\": 11,\n",
    "            }\n",
    "        )\n",
    "feature_names = features.columns\n",
    "\n",
    "speed_ranges = [speed for speed in np.unique(features[\"VehMaxSpeed\"])]\n",
    "speed_series = pd.Series(speed_ranges)\n",
    "mapping = {speed_range: i + 1 for i, speed_range in enumerate(speed_ranges)}\n",
    "features[\"VehMaxSpeed\"] = features[\"VehMaxSpeed\"].map(mapping)\n",
    "features[\"SocioCateg\"] = features[\"SocioCateg\"].str.extract(\"(\\d+)\").astype(int)\n",
    "\n",
    "cat_features = [\n",
    "            \"HasKmLimit\",\n",
    "            \"Gender\",\n",
    "            \"MariStat\",\n",
    "            \"VehUsage\",\n",
    "            \"VehBody\",\n",
    "            \"VehPrice\",\n",
    "            \"VehEngine\",\n",
    "            \"VehEnergy\",\n",
    "            \"VehClass\",\n",
    "            \"SocioCateg\"\n",
    "        ]\n",
    "\n",
    "num_features = [\n",
    "            feature for feature in features.columns if feature not in cat_features\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split and preprocess the data\n",
    "x_train, x_val, x_test, y_train, y_val, y_test, \\\n",
    "x_train_raw, x_val_raw, x_test_raw, \\\n",
    "num_features, cat_features, \\\n",
    "all_categories, ct = split_and_preprocess(\n",
    "    features, target, num_features, cat_features, seed=0\n",
    ")\n",
    "\n",
    "# Calculate and print statistics for y_train, y_val, y_test\n",
    "np.max(y_train), np.median(y_train), np.max(y_val), np.median(y_val), np.max(y_test), np.median(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use lowercase \"x_train\" \"y_train\" for pandas dataframes\n",
    "# and uppercase \"X_train\" \"Y_train\" for tensors.\n",
    "X_train = torch.Tensor(x_train.values)\n",
    "Y_train = torch.Tensor(y_train.values)\n",
    "X_val = torch.Tensor(x_val.values)\n",
    "Y_val = torch.Tensor(y_val.values)\n",
    "X_test = torch.Tensor(x_test.values)\n",
    "Y_test = torch.Tensor(y_test.values)\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train, Y_train)\n",
    "val_dataset = torch.utils.data.TensorDataset(X_val, Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sec 6.2: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = False\n",
    "tuning = False\n",
    "shap_run = False\n",
    "distribution = \"gamma\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"\\n\\nTraining GLM\\n\")\n",
    "\n",
    "torch.manual_seed(23)\n",
    "glm = GLM(X_train.shape[1], distribution = distribution)\n",
    "if training:\n",
    "    train(\n",
    "        glm,\n",
    "        gaussian_deviance_loss if distribution == \"gaussian\" else gamma_deviance_loss,\n",
    "        train_dataset,\n",
    "        val_dataset,\n",
    "        log_interval = 10,\n",
    "        epochs=5000,\n",
    "        lr=0.001,\n",
    "        patience=100,\n",
    "        batch_size=100,\n",
    "    )\n",
    "    glm.update_dispersion(X_train, Y_train)\n",
    "    glm.eval()\n",
    "    torch.save(glm.state_dict(), \"models/real/glm.pt\")\n",
    "else:\n",
    "    glm.load_state_dict(torch.load(\"models/real/glm.pt\"))\n",
    "    glm.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tuning:\n",
    "    space_cann_real = [\n",
    "        Integer(1, 6, name='num_hidden_layers'),\n",
    "        Categorical([32, 64, 128, 256, 512], name='hidden_size'),\n",
    "        Real(0.0, 0.5, name='dropout_rate'),\n",
    "        Real(0.0001, 0.01, name='lr'),\n",
    "        Categorical([64, 128, 256, 512], name='batch_size'),\n",
    "    ]\n",
    "\n",
    "    # Run Bayesian optimization\n",
    "    res_cann_real = skopt.gp_minimize(\n",
    "        lambda params: objective_cann(params,\n",
    "                                    X_train, Y_train, X_val, Y_val, train_dataset, val_dataset, 'gamma'),\n",
    "        space_cann_real,\n",
    "        n_calls=200,\n",
    "        n_random_starts=25,\n",
    "        random_state=0,\n",
    "        verbose=True\n",
    "    )\n",
    "    best_cann_paras = res_cann_real.x\n",
    "    print(best_cann_paras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"\\n\\nTraining CANN\\n\")\n",
    "\n",
    "# Identical hyperparamters from the paper\n",
    "if not tuning:\n",
    "    # Format: [hidden layers, neurons/layer,\n",
    "    #          dropout rate, learning rate, batch size]\n",
    "    best_cann_paras = [4, 512, 0.43674204603377464, 0.008896658675599278, 256]\n",
    "\n",
    "torch.manual_seed(23)\n",
    "cann = CANN(glm, num_hidden_layers=int(best_cann_paras[0]), hidden_size=int(best_cann_paras[1]),\n",
    "         dropout_rate = best_cann_paras[2])\n",
    "\n",
    "if training:\n",
    "    torch.manual_seed(23)\n",
    "    train(\n",
    "        cann,\n",
    "        gaussian_deviance_loss if distribution == \"gaussian\" else gamma_deviance_loss,\n",
    "        train_dataset,\n",
    "        val_dataset,\n",
    "        epochs=2000,\n",
    "        lr=best_cann_paras[-2],\n",
    "        patience=50,\n",
    "        batch_size=int(best_cann_paras[-1]),\n",
    "    )\n",
    "    cann.update_dispersion(X_train, Y_train)\n",
    "    cann.eval()\n",
    "    torch.save(cann.state_dict(), \"models/real/cann.pt\")\n",
    "else:\n",
    "    cann.load_state_dict(torch.load(\"models/real/cann.pt\"))\n",
    "    cann.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MDN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tuning:\n",
    "    space_mdn_real = [\n",
    "        Integer(1, 6, name='num_hidden_layers'),\n",
    "        Categorical([32, 64, 128, 256, 512], name='hidden_size'),\n",
    "        Real(0.0, 0.5, name='dropout_rate'),\n",
    "        Real(0.0001, 0.01, name='lr'),\n",
    "        Integer(2, 10, name='num_components'),\n",
    "        Categorical([64, 128, 256, 512], name='batch_size'),\n",
    "    ]\n",
    "\n",
    "    # Run Bayesian optimization\n",
    "    res_mdn_real = skopt.gp_minimize(\n",
    "        lambda params: objective_mdn(params,\n",
    "                                    X_train, Y_train, X_val, Y_val, train_dataset, val_dataset, 'gamma'),\n",
    "        space_mdn_real,\n",
    "        n_calls=200,\n",
    "        n_random_starts=25,\n",
    "        random_state=0,\n",
    "        verbose=True\n",
    "    )\n",
    "    best_mdn_paras = res_mdn_real.x\n",
    "    print(best_mdn_paras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"\\n\\nTraining MDN\\n\")\n",
    "\n",
    "# Identical hyperparameters from the paper\n",
    "if not tuning:\n",
    "    # Format: [hidden layers, neurons/layer,\n",
    "    #          dropout rate, learning rate,\n",
    "    #          components, batch size]\n",
    "    best_mdn_paras = [3, 256, 0.43747364699537183, 0.008452597861700977, 4, 256]\n",
    "    \n",
    "torch.manual_seed(23)\n",
    "mdn = MDN(X_train.shape[1], num_components=int(best_mdn_paras[-2]), hidden_size=int(best_mdn_paras[1]),\n",
    "            num_hidden_layers=int(best_mdn_paras[0]), dropout_rate = best_mdn_paras[2],\\\n",
    "            distribution= distribution)\n",
    "\n",
    "if training:  \n",
    "    torch.manual_seed(23)\n",
    "    train(\n",
    "        mdn,\n",
    "        gaussian_mdn_loss if distribution == \"gaussian\" else gamma_mdn_loss,\n",
    "        train_dataset,\n",
    "        val_dataset,\n",
    "        lr=best_mdn_paras[3],\n",
    "        batch_size=int(best_mdn_paras[-1]),\n",
    "        epochs=2000,\n",
    "        patience=50,\n",
    "    )\n",
    "    mdn.eval()\n",
    "    torch.save(mdn.state_dict(), \"models/real/mdn.pt\")\n",
    "else:\n",
    "    mdn.load_state_dict(torch.load(\"models/real/mdn.pt\"))\n",
    "    mdn.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tuning:\n",
    "    space_ddr_real = [\n",
    "        Integer(1, 6, name='num_hidden_layers'),\n",
    "        Categorical([32, 64, 128, 256, 512], name='hidden_size'),\n",
    "        Real(0.0, 0.5, name='dropout_rate'),\n",
    "        Real(0.0002, 0.01, name='lr'),\n",
    "        Categorical([0.05, 0.075, 0.1, 0.125, 0.15], name='proportion'),\n",
    "        Categorical([64, 128, 256, 512], name='batch_size'),\n",
    "    ]\n",
    "\n",
    "    # Run Bayesian optimization\n",
    "    res_ddr_real = skopt.gp_minimize(\n",
    "        lambda params: objective_ddr(params, X_train, Y_train, X_val, Y_val, train_dataset, val_dataset),\n",
    "        space_ddr_real,\n",
    "        n_calls=200,\n",
    "        n_random_starts=25,\n",
    "        random_state=0,\n",
    "        verbose=True\n",
    "    )\n",
    "    best_ddr_paras = res_ddr_real.x\n",
    "    print(best_ddr_paras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"\\n\\nTraining DDR\\n\")\n",
    "\n",
    "# Identical hyperparamters from the paper\n",
    "if not tuning:\n",
    "    # Format: [hidden layers, neurons/layer,\n",
    "    #          dropout rate, learning rate,\n",
    "    #          cutpoints proportion, batch size]\n",
    "    best_ddr_paras = [1, 512, 0.5, 0.005757483612427741, 0.15, 256]\n",
    "    \n",
    "cutpoints_DDR = ddr_cutpoints(c_0 = np.min(y_train) * 1.05 if np.min(y_train) < 0 else 0.0,\n",
    "                              c_K = np.max(y_train) * 1.05, \n",
    "                              y = y_train,\n",
    "                              p = best_ddr_paras[-2])\n",
    "\n",
    "torch.manual_seed(23)\n",
    "ddr = DDR(X_train.shape[1], cutpoints = cutpoints_DDR, hidden_size=int(best_ddr_paras[1]),\n",
    "            num_hidden_layers=int(best_ddr_paras[0]), dropout_rate = best_ddr_paras[2])\n",
    "\n",
    "if training:\n",
    "    torch.manual_seed(23)\n",
    "    train(\n",
    "        ddr,\n",
    "        ddr_loss,\n",
    "        train_dataset,\n",
    "        val_dataset, \n",
    "        lr=0.0005,\n",
    "        batch_size=100,\n",
    "        log_interval=1,\n",
    "        patience=30,\n",
    "        epochs=1000,\n",
    "    )\n",
    "    ddr.eval()\n",
    "    torch.save(ddr.state_dict(), \"models/real/ddr.pt\")\n",
    "else:\n",
    "    ddr.load_state_dict(torch.load(\"models/real/ddr.pt\"))\n",
    "    ddr.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DRN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tuning:\n",
    "    space_drn_real = [\n",
    "        Integer(1, 6, name='num_hidden_layers'),\n",
    "        Categorical([32, 64, 128, 256, 512], name='hidden_size'),\n",
    "        Real(0.0, 0.5, name='dropout_rate'),\n",
    "        Real(0.0002, 0.01, name='lr', prior = 'log-uniform'),\n",
    "        Real(1e-6, 1e-1, name='kl_alpha', prior = 'log-uniform'),\n",
    "        Categorical([0, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1], name='mean_alpha'),\n",
    "        Categorical([0, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1], name='dv_alpha'),\n",
    "        Categorical([64, 128, 256, 512], name='batch_size'),\n",
    "        Categorical([0.1, 0.125, 0.15], name='proportion'),\n",
    "        Categorical([1, 3, 5], name='min_observation'),\n",
    "    ]\n",
    "\n",
    "    # Run Bayesian optimization\n",
    "    res_drn_real = skopt.gp_minimize(\n",
    "        lambda params: objective_drn(params,\n",
    "                                    X_train=X_train,\n",
    "                                    Y_train=Y_train,\n",
    "                                    X_val=X_val,\n",
    "                                    Y_val=Y_val,\n",
    "                                    train_dataset=train_dataset,\n",
    "                                    val_dataset=val_dataset,\n",
    "                                    patience = 50,\n",
    "                                    kl_direction= 'forwards'),\n",
    "        space_drn_real,\n",
    "        n_calls=200,\n",
    "        n_random_starts=30,\n",
    "        random_state=0,\n",
    "        verbose=True\n",
    "    )\n",
    "    best_drn_paras = res_drn_real.x\n",
    "    print(best_drn_paras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"\\n\\nTraining DRN\\n\")\n",
    "\n",
    "# Identical hyperparamters from the paper\n",
    "if not tuning:\n",
    "  # Format: [hidden layers, neurons/layer,\n",
    "  #          dropout rate, learning rate,\n",
    "  #          kl penalty, mean penalty, roughnesss penalty,\n",
    "  #           batch size, proportion, minimum number of observations]\n",
    "    best_drn_paras = [2, 512,\n",
    "                    0.26987049089983844, 0.002907776355380247,\n",
    "                    0.0016204637505694557, 1e-06, 1e-05,\n",
    "                    512, 0.125, 3]\n",
    "\n",
    "cutpoints_DRN = drn_cutpoints(c_0 = np.min(Y_train.detach().numpy()) * 1.05 if np.min(Y_train.detach().numpy()) < 0 else 0.0,\n",
    "                              c_K = np.max(Y_train.detach().numpy()) * 1.05,\n",
    "                              p = best_drn_paras[-2],\n",
    "                              y = Y_train.detach().numpy(),\n",
    "                              min_obs = int(best_drn_paras[-1]))\n",
    "\n",
    "torch.manual_seed(23)\n",
    "drn = DRN(num_features = X_train.shape[1], cutpoints = cutpoints_DRN, glm = glm,\\\n",
    "                    hidden_size=int(best_drn_paras[1]), num_hidden_layers=int(best_drn_paras[0]),\n",
    "                      baseline_start = False,  dropout_rate = best_drn_paras[2])\n",
    "if training:\n",
    "    torch.manual_seed(23)\n",
    "    train(\n",
    "            model=drn,\n",
    "            criterion=lambda pred, y: drn_loss(pred, y, kl_alpha = best_drn_paras[4], #2e-4\n",
    "                                                mean_alpha = best_drn_paras[5],  #\n",
    "                                                tv_alpha = 0,\n",
    "                                                 dv_alpha = best_drn_paras[6]),   \n",
    "            train_dataset=train_dataset,\n",
    "            val_dataset=val_dataset,\n",
    "            batch_size=int(best_drn_paras[7]),\n",
    "            epochs=2000,\n",
    "            patience=50,\n",
    "            lr=best_drn_paras[3],\n",
    "            print_details=True,\n",
    "            log_interval=1,\n",
    "    )\n",
    "    drn.eval()\n",
    "    torch.save(drn.state_dict(), \"models/real/drn.pt\")\n",
    "else:\n",
    "    drn.load_state_dict(torch.load(\"models/real/drn.pt\"))\n",
    "    drn.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sec 6.3: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"GLM\", \"CANN\", \"MDN\", \"DDR\", \"DRN\"]\n",
    "models = [glm, cann, mdn, ddr, drn]\n",
    "\n",
    "print(\"Generating distributional forecasts\")\n",
    "dists_train = {}\n",
    "dists_val = {}\n",
    "dists_test = {}\n",
    "\n",
    "for name, model in zip(names, models):\n",
    "    print(f\"- {name}\")\n",
    "    dists_train[name] = model.distributions(X_train)\n",
    "    dists_val[name] = model.distributions(X_val)\n",
    "    dists_test[name] = model.distributions(X_test)\n",
    "\n",
    "print(\"Calculating CDF over a grid\")\n",
    "GRID_SIZE = 3000  # Increase this to get more accurate CRPS estimates\n",
    "grid = torch.linspace(0, np.max(y_train) * 1.1, GRID_SIZE).unsqueeze(-1)\n",
    "\n",
    "cdfs_train = {}\n",
    "cdfs_val = {}\n",
    "cdfs_test = {}\n",
    "\n",
    "for name, model in zip(names, models):\n",
    "    print(f\"- {name}\")\n",
    "    cdfs_train[name] = dists_train[name].cdf(grid)\n",
    "    cdfs_val[name] = dists_val[name].cdf(grid)\n",
    "    cdfs_test[name] = dists_test[name].cdf(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calculating negative loglikelihoods\")\n",
    "nlls_train = {}\n",
    "nlls_val = {}\n",
    "nlls_test = {}\n",
    "\n",
    "for name, model in zip(names, models):\n",
    "    nlls_train[name] = -dists_train[name].log_prob(Y_train).mean()\n",
    "    nlls_val[name] =-dists_val[name].log_prob(Y_val).mean()\n",
    "    nlls_test[name] = -dists_test[name].log_prob(Y_test).mean()\n",
    "    \n",
    "\n",
    "\n",
    "for nll_dict, df_name in zip([nlls_train, nlls_val, nlls_test],['training', 'val', 'test']):\n",
    "    print(f'NLL on {df_name} set')\n",
    "    for name, model in zip(names, models):\n",
    "        print(f\"{name}: {nll_dict[name].mean():.4f}\")\n",
    "    print(f'-------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nll_wilcoxon_test(dists_val, Y_val, 'Validation')\n",
    "nll_wilcoxon_test(dists_test, Y_test, 'Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calculating CRPS\")\n",
    "grid =grid.squeeze()\n",
    "crps_train ={}\n",
    "crps_val = {}\n",
    "crps_test = {}\n",
    "\n",
    "for name, model in zip(names, models):\n",
    "    crps_train[name] = crps(Y_train, grid, cdfs_train[name])\n",
    "    crps_val[name] = crps(Y_val, grid, cdfs_val[name])\n",
    "    crps_test[name] = crps(Y_test, grid, cdfs_test[name])\n",
    "\n",
    "for crps_dict, df_name in zip([crps_train, crps_val, crps_test],['training', 'val', 'test']):\n",
    "    print(f'CRPS on {df_name} set')\n",
    "    for name, model in zip(names, models):\n",
    "        print(f\"{name}: {crps_dict[name].mean():.4f}\")\n",
    "    print(f'------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crps_wilcoxon_test(cdfs_val, Y_val, grid, 'Validation')\n",
    "crps_wilcoxon_test(cdfs_test, Y_test, grid, 'Validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_train = {}\n",
    "rmse_val = {}\n",
    "rmse_test = {}\n",
    "\n",
    "for name, model in zip(names, models):\n",
    "    means_train = dists_train[name].mean\n",
    "    means_val = dists_val[name].mean\n",
    "    means_test = dists_test[name].mean\n",
    "    rmse_train[name] = rmse(y_train, means_train)\n",
    "    rmse_val[name] = rmse(y_val, means_val)\n",
    "    rmse_test[name] = rmse(y_test, means_test)\n",
    "\n",
    "for rmse_dict, df_name in zip([rmse_train, rmse_val, rmse_test], ['training', 'validation', 'test']):\n",
    "    print(f'RMSE on {df_name} set')\n",
    "    for name, model in zip(names, models):\n",
    "        print(f\"{name}: {rmse_dict[name].mean():.4f}\")\n",
    "    print(f'-------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_wilcoxon_test(dists_val, Y_val, 'Validation')\n",
    "rmse_wilcoxon_test(dists_test, Y_test, 'Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 90 Quantile Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ql_90_train = {}\n",
    "ql_90_val = {}\n",
    "ql_90_test = {}\n",
    "\n",
    "for features, response, dataset_name, ql_dict in zip(\n",
    "                            [X_train, X_val, X_test],\n",
    "                            [y_train, y_val, y_test],\n",
    "                            ['Training', 'Validation', 'Test'],\n",
    "                            [ql_90_train, ql_90_val, ql_90_test]):\n",
    "    print(f'{dataset_name} Dataset Quantile Loss(es)')\n",
    "    for model, model_name in zip(models, names):\n",
    "        ql_dict[model_name] = quantile_losses(\n",
    "                                            0.9,\n",
    "                                            model,\n",
    "                                            model_name,\n",
    "                                            features,\n",
    "                                            response,\n",
    "                                            max_iter = 1000,\n",
    "                                            tolerance = 1e-4,\\\n",
    "                                            l = torch.Tensor([0]),\\\n",
    "                                            u = torch.Tensor([np.max(y_train)+3*(np.max(y_train)-np.min(y_train))])\n",
    "                                            )\n",
    "    print(f\"----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ql90_wilcoxon_test(X_val, Y_val, 'Validation')\n",
    "ql90_wilcoxon_test(X_test, Y_test, 'Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latex_table(nlls_val, crps_val, rmse_val, ql_90_val,\\\n",
    "                         nlls_test, crps_test, rmse_test, ql_90_test,\\\n",
    "                        model_names, label_txt='Evaluation Metrics Table',\\\n",
    "                         caption_txt = 'Evaluation Metrics Table.',\\\n",
    "                           scaling_factor = 1.0):\n",
    "    header_row = (\"\\\\begin{center}\\n\"\n",
    "                +  \"\\captionof{table}{\" + f'{caption_txt}' + '}\\n'\n",
    "                + \"\\label{\" + f'{label_txt}' + '}\\n'\n",
    "                + \"\\scalebox{\" + f'{scaling_factor}' + '}{\\n'\n",
    "                + \"\\\\begin{tabular}{l|cccc|cccc}\\n\\\\toprule\\n\\\\toprule\\n\"\n",
    "                + \"&  \\multicolumn{4}{c}{$\\mathcal{D}_{\\\\text{Validation}}$}\"\n",
    "                + \"& \\multicolumn{4}{c}{ $\\mathcal{D}_{\\\\text{Test}}$}\\\\\\\\ \\n\"\n",
    "                + \" \\cmidrule{2-5}  \\cmidrule{6-9} $\\\\text{Model}$ $\\\\backslash$ $\\\\text{Metrics}$\"\n",
    "                + \" & NLL & CRPS & RMSE & 90\\% QL & NLL & CRPS & RMSE & 90\\% QL \\\\\\\\ \\\\midrule\")\n",
    "    rows = [header_row]\n",
    "\n",
    "    for name in model_names:\n",
    "        row = ( \n",
    "              f\"{name} &  {(nlls_val[name].mean()):.4f}\" \n",
    "              f\" &  {(crps_val[name].mean()):.4f} \"  \n",
    "              f\" & {(rmse_val[name].mean()):.4f} \"  \n",
    "              f\" & {(ql_90_val[name].mean()):.4f} \" \n",
    "              f\" & {(nlls_test[name].mean()):.4f} \"\n",
    "              f\" & {(crps_test[name].mean()):.4f} \" \n",
    "              f\" & {(rmse_test[name].mean()):.4f} \"  \n",
    "              f\" & {(ql_90_test[name].mean()):.4f} \\\\\\\\ \"  \n",
    "              )\n",
    "        rows.append(row)\n",
    "    \n",
    "    table = (\"\\n\".join(rows)  \n",
    "                  + \"\\n\\\\bottomrule\\n\\\\bottomrule\" \n",
    "                  + \"\\n\\\\end{tabular}\"\n",
    "                  +  \"\\n}\"\n",
    "                  + \"\\n\\end{center}\")\n",
    "    return table\n",
    "\n",
    "\n",
    "latex_table = generate_latex_table(nlls_val, crps_val, rmse_val, ql_90_val,\n",
    "                                   nlls_test, crps_test, rmse_test, ql_90_test, names,\n",
    "                                    label_txt='Evaluation Metrics',\n",
    "                                    caption_txt = 'Model comparisons based on various evaluation metrics.',\n",
    "                                    scaling_factor = 0.95 \n",
    "                                    )\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantile Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile_residuals_plots(quantile_points(cdfs_test, y_test, grid))\n",
    "plt.savefig(\"plots/real/Quantile Residuals Plot Real.png\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_plot(cdfs_test, y_test, grid)\n",
    "plt.savefig(\"plots/real/Calibration Plot Real.png\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sec 6.4: Interpretability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sec 6.4.1 Local Interpretability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Extreme Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_diff = drn.distributions(X_test).mean - glm.distributions(X_test).mean\n",
    "# Find the top 5 values and their indices\n",
    "values, indices = torch.topk(means_diff.view(-1), 3, sorted=True)\n",
    "multi_indices = np.unravel_index(indices.numpy(), means_diff.shape)\n",
    "\n",
    "print(multi_indices, means_diff[multi_indices])\n",
    "idx_first = multi_indices[0][0]\n",
    "idx_second = multi_indices[0][1]\n",
    "idx_third = multi_indices[0][2]\n",
    "y_test.values[multi_indices], drn.distributions(X_test).mean[multi_indices], glm.distributions(X_test).mean[multi_indices],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drn_explainer = DRNExplainer(drn, glm, cutpoints_DRN, x_train_raw, cat_features, all_categories, column_transformer=ct)  \n",
    "idx = idx_second\n",
    "drn_explainer.plot_dp_adjustment_shap(instance_raw = x_test_raw.iloc[idx:(idx+1)],\\\n",
    "                                       method = 'Kernel',\\\n",
    "                                       nsamples_background_fraction= 0.5, \\\n",
    "                                       top_K_features= 5,\\\n",
    "                                      labelling_gap = 0.1,\\\n",
    "                                        dist_property= 'Mean',\n",
    "                                        x_range = (0.0, 50.0),\n",
    "                                        y_range = (0.0, 0.75),\n",
    "                                        observation = Y_test[idx:(idx+1)],\n",
    "                                        density_transparency = 0.5,\n",
    "                                        adjustment= True,\n",
    "                                          shap_fontsize=15,\n",
    "                                          figsize = (7, 7),\n",
    "                                        plot_title = 'Explaining a Large Mean Adjustment',\n",
    "                                         legend_loc = 'upper left'\n",
    "                                          )\n",
    "\n",
    "plt.savefig(\"plots/(Real) Mean Adjustment SHAP.png\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drn_explainer = DRNExplainer(drn, glm, cutpoints_DRN, x_train_raw, cat_features, all_categories, column_transformer=ct)  \n",
    "idx = idx_second\n",
    "drn_explainer.plot_dp_adjustment_shap(instance_raw = x_test_raw.iloc[idx:(idx+1)],\\\n",
    "                                       method = 'Kernel',\\\n",
    "                                       nsamples_background_fraction= 0.5, \\\n",
    "                                       top_K_features= 5,\\\n",
    "                                      labelling_gap=0.1,\\\n",
    "                                        dist_property= 'Mean',\n",
    "                                        #other_df_models = [mdn, ddr], model_names = [\"MDN\", \"DDR\"],\\\n",
    "                                        x_range = (0.0, 50.0),\n",
    "                                        y_range = (0.0, 0.75),\n",
    "                                        observation = Y_test[idx:(idx+1)],\n",
    "                                        density_transparency = 0.5,\n",
    "                                        adjustment= False,\n",
    "                                          shap_fontsize=15,\n",
    "                                         figsize = (7, 7),\n",
    "                                        plot_title = 'Explaining a Large Mean Prediction',\n",
    "                                         legend_loc = 'upper left'\n",
    "                                          )\n",
    "\n",
    "plt.savefig(\"plots/(Real) Mean Explanation SHAP.png\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Average Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean differences between DRN and GLM predictions\n",
    "means_diff = drn.distributions(X_test).mean - glm.distributions(X_test).mean\n",
    "\n",
    "# Find indices where the percentage change between means is betweenn than 30% and 50%\n",
    "valid_indices =  (0.4 < (torch.abs(means_diff) / glm.distributions(X_test).mean)) &  \\\n",
    "                 (0.8 > (torch.abs(means_diff) / glm.distributions(X_test).mean)) \n",
    "\n",
    "# Filter X_test, x_test_raw, and y_test based on these valid indices\n",
    "X_test_new = X_test[valid_indices]\n",
    "x_test_raw_new = x_test_raw.iloc[valid_indices.numpy()]\n",
    "y_test_new = Y_test[valid_indices]\n",
    "\n",
    "# Recalculate mean differences with the filtered dataset\n",
    "means_diff_new = drn.distributions(X_test_new).mean - glm.distributions(X_test_new).mean\n",
    "glm_means_new = glm.distributions(X_test_new).mean\n",
    "\n",
    "# Find instances where the GLM predictions are close to the actual y values\n",
    "y_diff = torch.abs(y_test_new - glm_means_new)\n",
    "close_y_indices = y_diff < 0.3 * torch.abs(y_test_new)  # Assuming 30% closeness threshold\n",
    "\n",
    "# Filter further based on the closeness of GLM predictions to y_test\n",
    "X_test_final = X_test_new[close_y_indices]\n",
    "means_diff_final = means_diff_new[close_y_indices]\n",
    "y_test_final = y_test_new[close_y_indices]\n",
    "glm_means_final = glm_means_new[close_y_indices]\n",
    "drn_means_final = drn.distributions(X_test_final).mean\n",
    "\n",
    "# Ensure we have enough data points after filtering\n",
    "if len(means_diff_final) >= 4:\n",
    "    # Find the top 4 values and their indices based on the filtered dataset\n",
    "    values, indices = torch.topk(torch.abs(means_diff_final).view(-1), 4, largest=False)\n",
    "\n",
    "    # Extract the original indices for the closest Four instances\n",
    "    original_indices = valid_indices.nonzero(as_tuple=True)[0][close_y_indices][indices]\n",
    "\n",
    "    idx_first = original_indices[0].item()\n",
    "    idx_second = original_indices[1].item()\n",
    "    idx_third = original_indices[2].item()\n",
    "    idx_forth = original_indices[3].item()\n",
    "\n",
    "    # Output the results for the selected instances\n",
    "    print(\"Original Indices:\", idx_first, idx_second)\n",
    "    print(\"Actual y values:\", y_test.values[idx_first], y_test.values[idx_second])\n",
    "    print(\"DRN mean predictions:\", drn.distributions(X_test).mean[idx_first].item(), drn.distributions(X_test).mean[idx_second].item())\n",
    "    print(\"GLM mean predictions:\", glm.distributions(X_test).mean[idx_first].item(), glm.distributions(X_test).mean[idx_second].item())\n",
    "else:\n",
    "    print(\"Not enough data points meet the criteria.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drn_explainer = DRNExplainer(drn, glm, cutpoints_DRN, x_train_raw, cat_features, all_categories, column_transformer=ct)  \n",
    "idx = idx_first\n",
    "drn_explainer.plot_dp_adjustment_shap(instance_raw = x_test_raw.iloc[idx:(idx+1)],\\\n",
    "                                       method = 'Kernel',\\\n",
    "                                       nsamples_background_fraction= 0.5, \\\n",
    "                                       top_K_features= 5,\\\n",
    "                                      labelling_gap=0.1,\\\n",
    "                                        dist_property= 'Mean',\n",
    "                                        #other_df_models = [mdn, ddr], model_names = [\"MDN\", \"DDR\"],\\\n",
    "                                        x_range = (0.0, 6.5),\n",
    "                                        y_range = (0.0, 2.5),\n",
    "                                        observation = Y_test[idx:(idx+1)],\n",
    "                                        density_transparency = 0.5,\n",
    "                                        adjustment= True,\n",
    "                                          shap_fontsize=15,\n",
    "                                         figsize = (7, 7),\n",
    "                                        plot_title = 'Explaining an Average Mean Adjustment',\n",
    "                                         legend_loc = 'upper left'\n",
    "                                          )\n",
    "\n",
    "plt.savefig(\"plots/(Real) Average Mean Adjustment SHAP.png\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Mild Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_diff = drn.distributions(X_test).mean - glm.distributions(X_test).mean\n",
    "\n",
    "valid_indices =  (0.1 < (torch.abs(means_diff) / glm.distributions(X_test).mean)) &  \\\n",
    "                 (0.3 > (torch.abs(means_diff) / glm.distributions(X_test).mean))\n",
    "\n",
    "X_test_new = X_test[valid_indices]\n",
    "x_test_raw_new = x_test_raw.iloc[valid_indices.numpy()]\n",
    "y_test_new = Y_test[valid_indices]\n",
    "\n",
    "means_diff_new = drn.distributions(X_test_new).mean - glm.distributions(X_test_new).mean\n",
    "glm_means_new = glm.distributions(X_test_new).mean\n",
    "\n",
    "y_diff = torch.abs(y_test_new - glm_means_new)\n",
    "close_y_indices = y_diff < 0.2 * torch.abs(y_test_new)  # Assuming 20% closeness threshold\n",
    "\n",
    "X_test_final = X_test_new[close_y_indices]\n",
    "means_diff_final = means_diff_new[close_y_indices]\n",
    "y_test_final = y_test_new[close_y_indices]\n",
    "glm_means_final = glm_means_new[close_y_indices]\n",
    "drn_means_final = drn.distributions(X_test_final).mean\n",
    "\n",
    "if len(means_diff_final) >= 4:\n",
    "    values, indices = torch.topk(torch.abs(means_diff_final).view(-1), 4, largest=False)\n",
    "    original_indices = valid_indices.nonzero(as_tuple=True)[0][close_y_indices][indices]\n",
    "\n",
    "    idx_first = original_indices[0].item()\n",
    "    idx_second = original_indices[1].item()\n",
    "    idx_third = original_indices[2].item()\n",
    "    idx_forth = original_indices[3].item()\n",
    "\n",
    "    # Output the results for the selected instances\n",
    "    print(\"Original Indices:\", idx_first, idx_second)\n",
    "    print(\"Actual y values:\", y_test.values[idx_first], y_test.values[idx_second])\n",
    "    print(\"DRN mean predictions:\", drn.distributions(X_test).mean[idx_first].item(), drn.distributions(X_test).mean[idx_second].item())\n",
    "    print(\"GLM mean predictions:\", glm.distributions(X_test).mean[idx_first].item(), glm.distributions(X_test).mean[idx_second].item())\n",
    "else:\n",
    "    print(\"Not enough data points meet the criteria.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drn_explainer = DRNExplainer(drn, glm, cutpoints_DRN, x_train_raw, cat_features, all_categories, column_transformer=ct)  \n",
    "idx = idx_second\n",
    "drn_explainer.plot_dp_adjustment_shap(instance_raw = x_test_raw.iloc[idx:(idx+1)],\\\n",
    "                                       method = 'Kernel',\\\n",
    "                                       nsamples_background_fraction= 0.5, \\\n",
    "                                       top_K_features= 5,\\\n",
    "                                      labelling_gap=0.1,\\\n",
    "                                        dist_property= 'Mean',\n",
    "                                        #other_df_models = [mdn, ddr], model_names = [\"MDN\", \"DDR\"],\\\n",
    "                                        x_range = (0.0, 6.0),\n",
    "                                        y_range = (0.0, 2.0),\n",
    "                                        observation = Y_test[idx:(idx+1)],\n",
    "                                        density_transparency = 0.5,\n",
    "                                        adjustment= True,\n",
    "                                          shap_fontsize=15,\n",
    "                                         figsize = (7, 7),\n",
    "                                        plot_title = 'Explaining a Mild Mean Adjustment',\n",
    "                                         legend_loc = 'upper left'\n",
    "                                          )\n",
    "\n",
    "plt.savefig(\"plots/(Real) Mild Mean Adjustment SHAP.png\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CDF Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drn_explainer = DRNExplainer(\n",
    "    drn, glm, cutpoints_DRN, x_train_raw, cat_features, all_categories, column_transformer=ct\n",
    ")\n",
    "\n",
    "idx = idx_first\n",
    "drn_explainer.cdf_plot(\n",
    "    instance = x_test_raw.iloc[idx:(idx+1)],\n",
    "    method='Kernel',\n",
    "    nsamples_background_fraction=0.2,\n",
    "    top_K_features=5,\n",
    "    labelling_gap=0.1,\n",
    "    dist_property='90% Quantile',\n",
    "    quantile_bounds = (torch.Tensor([cutpoints_DRN[0]]), torch.Tensor([cutpoints_DRN[-1]])),\n",
    "    x_range=(0.0, 8.5),\n",
    "    y_range=(0., 1.0),\n",
    "    density_transparency=0.9,\n",
    "    adjustment=True,\n",
    "    shap_fontsize=15,\n",
    "    figsize=(7, 7),\n",
    "    plot_title='90% Quantile Adjustment Explanation',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sec 6.4.2: Global Interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if shap_run:\n",
    "  drn_explainer = DRNExplainer(drn, glm, cutpoints_DRN, x_train_raw, cat_features, all_categories, ct)  \n",
    "  kernel_shap_drn = drn_explainer.kernel_shap(\n",
    "                                              explaining_data = x_test_raw,\n",
    "                                              distributional_property= 'Mean',\n",
    "                                              nsamples_background_fraction = 0.2,\n",
    "                                              adjustment= True,\n",
    "                                              glm_output= True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if shap_run:\n",
    "    kernel_shap_drn.global_importance_plot(num_features+cat_features, output = 'drn')\n",
    "    plt.tight_layout() \n",
    "    plt.savefig(\"plots/(Real) Global Importance.png\");\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    kernel_shap_drn.beeswarm_plot(num_features+cat_features, output = 'drn')\n",
    "    plt.tight_layout() \n",
    "    plt.savefig(\"plots/(Real) Beeswarm Summary Plot.png\");\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    kernel_shap_drn.shap_dependence_plot(('MariStat', 'Exposure'), output = 'drn')\n",
    "    plt.tight_layout() \n",
    "    plt.savefig(\"plots/(SHAP Dependence) MariState X Exposure.png\");\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    kernel_shap_drn.shap_dependence_plot(('MariStat', 'LicAge'), output = 'drn')\n",
    "    plt.tight_layout() \n",
    "    plt.savefig(\"plots/(SHAP Dependence) MariState X LicAge.png\");\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if shap_run:\n",
    "    kernel_shap_drn.global_importance_plot(num_features+cat_features, output = 'value')\n",
    "    plt.savefig(\"plots/(Real Adjustment) Global Importance.png\");\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    kernel_shap_drn.beeswarm_plot(num_features+cat_features, output = 'value')\n",
    "    plt.savefig(\"plots/(Real Adjustment) Beeswarm Summary Plot.png\");\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if shap_run:\n",
    "    kernel_shap_drn.shap_dependence_plot(('VehEnergy', 'Exposure'), output = 'value')\n",
    "    plt.savefig(\"plots/(SHAP Adjustment) VehEnergy X Exposure.png\");\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    kernel_shap_drn.shap_dependence_plot(('RiskVar', 'Exposure'), output = 'value')\n",
    "    plt.savefig(\"plots/(SHAP Adjustment) RiskVar X Exposure.png\");\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    kernel_shap_drn.shap_dependence_plot(('LicAge', 'DrivAge'), output = 'value')\n",
    "    plt.savefig(\"plots/(SHAP Adjustment) LicAge X DrivAge.png\");\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
