{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "from drn import *\n",
    "\n",
    "from generate_synthetic_dataset import generate_synthetic_gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = Path(\"models/reg\")\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, target, means, dispersion = generate_synthetic_gaussian(40000)\n",
    "df = pd.concat([features, target], axis=1)\n",
    "df.to_csv(\"reg.csv\", index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, x_test, y_train, y_val, y_test,\\\n",
    "      x_train_raw, x_val_raw, x_test_raw,\\\n",
    "          num_features, cat_features,\\\n",
    "             all_categories, ct =\\\n",
    "                split_and_preprocess(features, target, ['X_1', 'X_2'], [], seed = 0, num_standard = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.Tensor(x_train.values)\n",
    "Y_train = torch.Tensor(y_train.values)\n",
    "X_val = torch.Tensor(x_val.values)\n",
    "Y_val = torch.Tensor(y_val.values)\n",
    "X_test = torch.Tensor(x_test.values)\n",
    "Y_test = torch.Tensor(y_test.values)\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train, Y_train)\n",
    "val_dataset = torch.utils.data.TensorDataset(X_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution = \"gaussian\" # distributional assumption for the GLM, CANN, MDN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm = GLM.from_statsmodels(X_train, Y_train, distribution=distribution)\n",
    "torch.save(glm, MODEL_DIR / \"glm.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutpoints_DRN = drn_cutpoints(c_0 = np.min(y_train) * 1.05 if np.min(y_train) < 0 else 0.0,\n",
    "                              c_K = np.max(y_train) * 1.05,\n",
    "                              p = 0.01,\n",
    "                              y = y_train,\n",
    "                              min_obs = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) No Regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(23)\n",
    "drn_no_penalty = DRN(num_features = x_train.shape[1], cutpoints = cutpoints_DRN, glm = glm,\n",
    "     hidden_size=100, num_hidden_layers=2, baseline_start = False, dropout_rate = 0.2)\n",
    "train(\n",
    "    drn_no_penalty,\n",
    "    lambda pred, y : drn_loss(pred, y, kl_alpha = 0,\n",
    "                                            mean_alpha = 0,\n",
    "                                            dv_alpha = 0,\n",
    "                                            tv_alpha = 0),   \n",
    "    train_dataset,\n",
    "    val_dataset, \n",
    "    lr=0.001, #lr = 0.0002\n",
    "    batch_size= 200, #batch_size = 50\n",
    "    log_interval=1,\n",
    "    patience=30,\n",
    "    epochs=1000,\n",
    ")\n",
    "torch.save(drn_no_penalty, MODEL_DIR / \"drn_no_penalty.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) Small KL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(23)\n",
    "drn_kl_penalty = DRN(num_features = x_train.shape[1], cutpoints = cutpoints_DRN, glm = glm,\\\n",
    "     hidden_size=128, num_hidden_layers=2, baseline_start = False,  dropout_rate = 0.2)\n",
    "train(\n",
    "    drn_kl_penalty,\n",
    "    lambda pred, y : drn_loss(pred, y, kl_alpha = 0.001,\n",
    "                                            mean_alpha = 0,  #5e-2\n",
    "                                            dv_alpha = 0, #5e-4\n",
    "                                            tv_alpha = 0),   \n",
    "    train_dataset,\n",
    "    val_dataset, \n",
    "    lr=0.001, #lr = 0.0002\n",
    "    batch_size= 200, #batch_size = 50\n",
    "    log_interval=1,\n",
    "    patience=10,\n",
    "    epochs=1000,\n",
    ")\n",
    "torch.save(drn_kl_penalty, MODEL_DIR / \"drn_kl_penalty.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c) Excessive Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(23)\n",
    "drn_dv_large_penalty = DRN(num_features = x_train.shape[1], cutpoints = cutpoints_DRN, glm = glm,\\\n",
    "     hidden_size=128, num_hidden_layers=2, baseline_start = True,  dropout_rate = 0.2)\n",
    "train(\n",
    "    drn_dv_large_penalty,\n",
    "    lambda pred, y : drn_loss(pred, y, kl_alpha = 0, \n",
    "                                        mean_alpha = 0,  \n",
    "                                        dv_alpha = 10, \n",
    "                                        tv_alpha = 0),   \n",
    "    train_dataset,\n",
    "    val_dataset, \n",
    "    lr=0.01, \n",
    "    batch_size= 300,\n",
    "    log_interval=1,\n",
    "    patience=10,\n",
    "    epochs=1000,\n",
    ")\n",
    "torch.save(drn_dv_large_penalty, MODEL_DIR / \"drn_dv_large_penalty.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (d) Perfect Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(23)\n",
    "drn_everything = DRN(num_features = x_train.shape[1], cutpoints = cutpoints_DRN, glm = glm,\\\n",
    "     hidden_size=128, num_hidden_layers=2, baseline_start = False,  dropout_rate = 0.2)\n",
    "train(\n",
    "    drn_everything,\n",
    "    lambda pred, y : drn_loss(pred, y, kl_alpha = 1e-3, \n",
    "                                            mean_alpha = 0,  \n",
    "                                            dv_alpha = 5e-4,\n",
    "                                            tv_alpha = 0),   \n",
    "    train_dataset,\n",
    "    val_dataset, \n",
    "    lr=0.001, \n",
    "    batch_size= 100, \n",
    "    log_interval=1,\n",
    "    patience=10,\n",
    "    epochs=1000,\n",
    ")\n",
    "torch.save(drn_everything, MODEL_DIR / \"drn_everything.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
