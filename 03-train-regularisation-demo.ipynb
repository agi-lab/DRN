{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "assert load_dotenv(find_dotenv(usecwd=False)), \"The .env file was not loaded.\"\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from drn import *\n",
    "\n",
    "torch.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"data/processed/reg\")\n",
    "x_train = pd.read_csv(DATA_DIR / \"x_train.csv\")\n",
    "x_val = pd.read_csv(DATA_DIR / \"x_val.csv\")\n",
    "y_train = pd.read_csv(DATA_DIR / \"y_train.csv\")\n",
    "y_val = pd.read_csv(DATA_DIR / \"y_val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = Path(\"models/reg\")\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.Tensor(x_train.values)\n",
    "Y_train = torch.Tensor(y_train.values)\n",
    "X_val = torch.Tensor(x_val.values)\n",
    "Y_val = torch.Tensor(y_val.values)\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train, Y_train)\n",
    "val_dataset = torch.utils.data.TensorDataset(X_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution = \"gaussian\"  # distributional assumption for the GLM, CANN, MDN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm = GLM.from_statsmodels(X_train, Y_train, distribution=distribution)\n",
    "torch.save(glm, MODEL_DIR / \"glm.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutpoints_DRN = drn_cutpoints(\n",
    "    c_0=np.min(y_train) * 1.05 if np.min(y_train) < 0 else 0.0,\n",
    "    c_K=np.max(y_train) * 1.05,\n",
    "    y=y_train,\n",
    "    proportion=0.01,\n",
    "    min_obs=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) No Regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(23)\n",
    "drn_no_penalty = DRN(\n",
    "    num_features=x_train.shape[1],\n",
    "    cutpoints=cutpoints_DRN,\n",
    "    glm=glm,\n",
    "    hidden_size=100,\n",
    "    num_hidden_layers=2,\n",
    "    baseline_start=False,\n",
    "    dropout_rate=0.2,\n",
    ")\n",
    "train(\n",
    "    drn_no_penalty,\n",
    "    lambda pred, y: drn_loss(pred, y, kl_alpha=0, mean_alpha=0, dv_alpha=0, tv_alpha=0),\n",
    "    train_dataset,\n",
    "    val_dataset,\n",
    "    lr=0.001,  # lr = 0.0002\n",
    "    batch_size=200,  # batch_size = 50\n",
    "    log_interval=1,\n",
    "    patience=30,\n",
    "    epochs=1000,\n",
    ")\n",
    "torch.save(drn_no_penalty, MODEL_DIR / \"drn_no_penalty.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) Small KL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(23)\n",
    "drn_kl_penalty = DRN(\n",
    "    num_features=x_train.shape[1],\n",
    "    cutpoints=cutpoints_DRN,\n",
    "    glm=glm,\n",
    "    hidden_size=128,\n",
    "    num_hidden_layers=2,\n",
    "    baseline_start=False,\n",
    "    dropout_rate=0.2,\n",
    ")\n",
    "train(\n",
    "    drn_kl_penalty,\n",
    "    lambda pred, y: drn_loss(\n",
    "        pred, y, kl_alpha=0.001, mean_alpha=0, dv_alpha=0, tv_alpha=0  # 5e-2  # 5e-4\n",
    "    ),\n",
    "    train_dataset,\n",
    "    val_dataset,\n",
    "    lr=0.001,  # lr = 0.0002\n",
    "    batch_size=200,  # batch_size = 50\n",
    "    log_interval=1,\n",
    "    patience=10,\n",
    "    epochs=1000,\n",
    ")\n",
    "torch.save(drn_kl_penalty, MODEL_DIR / \"drn_kl_penalty.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c) Excessive Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(23)\n",
    "drn_dv_large_penalty = DRN(\n",
    "    num_features=x_train.shape[1],\n",
    "    cutpoints=cutpoints_DRN,\n",
    "    glm=glm,\n",
    "    hidden_size=128,\n",
    "    num_hidden_layers=2,\n",
    "    baseline_start=True,\n",
    "    dropout_rate=0.2,\n",
    ")\n",
    "train(\n",
    "    drn_dv_large_penalty,\n",
    "    lambda pred, y: drn_loss(\n",
    "        pred, y, kl_alpha=0, mean_alpha=0, dv_alpha=10, tv_alpha=0\n",
    "    ),\n",
    "    train_dataset,\n",
    "    val_dataset,\n",
    "    lr=0.01,\n",
    "    batch_size=300,\n",
    "    log_interval=1,\n",
    "    patience=10,\n",
    "    epochs=1000,\n",
    ")\n",
    "torch.save(drn_dv_large_penalty, MODEL_DIR / \"drn_dv_large_penalty.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (d) Perfect Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(23)\n",
    "drn_everything = DRN(\n",
    "    num_features=x_train.shape[1],\n",
    "    cutpoints=cutpoints_DRN,\n",
    "    glm=glm,\n",
    "    hidden_size=128,\n",
    "    num_hidden_layers=2,\n",
    "    baseline_start=False,\n",
    "    dropout_rate=0.2,\n",
    ")\n",
    "train(\n",
    "    drn_everything,\n",
    "    lambda pred, y: drn_loss(\n",
    "        pred, y, kl_alpha=1e-3, mean_alpha=0, dv_alpha=5e-4, tv_alpha=0\n",
    "    ),\n",
    "    train_dataset,\n",
    "    val_dataset,\n",
    "    lr=0.001,\n",
    "    batch_size=100,\n",
    "    log_interval=1,\n",
    "    patience=10,\n",
    "    epochs=1000,\n",
    ")\n",
    "torch.save(drn_everything, MODEL_DIR / \"drn_everything.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
