{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "assert load_dotenv(find_dotenv(usecwd=False)), \"The .env file was not loaded.\"\n",
    "\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from drn import DRNExplainer, crps, rmse, split_and_preprocess\n",
    "from skopt.plots import plot_objective\n",
    "\n",
    "from analysis_utils import (\n",
    "    calibration_plot,\n",
    "    crps_wilcoxon_test,\n",
    "    generate_latex_table,\n",
    "    nll_wilcoxon_test,\n",
    "    ql90_wilcoxon_test,\n",
    "    quantile_losses_raw,\n",
    "    quantile_points,\n",
    "    quantile_residuals_plots,\n",
    "    rmse_wilcoxon_test,\n",
    ")\n",
    "from generate_synthetic_dataset import generate_synthetic_gamma_lognormal\n",
    "\n",
    "torch.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"savefig.dpi\"] = 300\n",
    "plt.rcParams[\"xtick.labelsize\"] = 15\n",
    "plt.rcParams[\"ytick.labelsize\"] = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = Path(\"models/synth\")\n",
    "PLOT_DIR = Path(\"plots/synth\")\n",
    "PLOT_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, target, means, dispersion = generate_synthetic_gamma_lognormal(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    x_train,\n",
    "    x_val,\n",
    "    x_test,\n",
    "    y_train,\n",
    "    y_val,\n",
    "    y_test,\n",
    "    x_train_raw,\n",
    "    x_val_raw,\n",
    "    x_test_raw,\n",
    "    num_features,\n",
    "    cat_features,\n",
    "    all_categories,\n",
    "    ct,\n",
    ") = split_and_preprocess(\n",
    "    features, target, [\"X_1\", \"X_2\"], [], seed=42, num_standard=False\n",
    ")\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.Tensor(x_train.values)\n",
    "Y_train = torch.Tensor(y_train.values)\n",
    "X_val = torch.Tensor(x_val.values)\n",
    "Y_val = torch.Tensor(y_val.values)\n",
    "X_test = torch.Tensor(x_test.values)\n",
    "Y_test = torch.Tensor(y_test.values)\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train, Y_train)\n",
    "val_dataset = torch.utils.data.TensorDataset(X_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm = torch.load(MODEL_DIR / \"glm.pkl\", weights_only=False)\n",
    "cann = torch.load(MODEL_DIR / \"cann.pkl\", weights_only=False)\n",
    "mdn = torch.load(MODEL_DIR / \"mdn.pkl\", weights_only=False)\n",
    "ddr = torch.load(MODEL_DIR / \"ddr.pkl\", weights_only=False)\n",
    "drn = torch.load(MODEL_DIR / \"drn.pkl\", weights_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sec 5.3.1: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"GLM\", \"CANN\", \"MDN\", \"DDR\", \"DRN\"]\n",
    "models = [glm, cann, mdn, ddr, drn]\n",
    "\n",
    "print(\"Generating distributional forecasts\")\n",
    "dists_train = {}\n",
    "dists_val = {}\n",
    "dists_test = {}\n",
    "\n",
    "for name, model in zip(names, models):\n",
    "    print(f\"- {name}\")\n",
    "    dists_train[name] = model.distributions(X_train)\n",
    "    dists_val[name] = model.distributions(X_val)\n",
    "    dists_test[name] = model.distributions(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calculating CDF over a grid\")\n",
    "GRID_SIZE = 3000  # Increase this to get more accurate CRPS estimates\n",
    "grid = torch.linspace(0, np.max(y_train) * 1.1, GRID_SIZE).unsqueeze(-1)\n",
    "\n",
    "cdfs_train = {}\n",
    "cdfs_val = {}\n",
    "cdfs_test = {}\n",
    "\n",
    "for name, model in zip(names, models):\n",
    "    print(f\"- {name}\")\n",
    "    cdfs_train[name] = dists_train[name].cdf(grid)\n",
    "    cdfs_val[name] = dists_val[name].cdf(grid)\n",
    "    cdfs_test[name] = dists_test[name].cdf(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calculating negative loglikelihoods\")\n",
    "nlls_train = {}\n",
    "nlls_val = {}\n",
    "nlls_test = {}\n",
    "\n",
    "for name, model in zip(names, models):\n",
    "    nlls_train[name] = -dists_train[name].log_prob(Y_train).mean()\n",
    "    nlls_val[name] = -dists_val[name].log_prob(Y_val).mean()\n",
    "    nlls_test[name] = -dists_test[name].log_prob(Y_test).mean()\n",
    "\n",
    "for nll_dict, df_name in zip(\n",
    "    [nlls_train, nlls_val, nlls_test], [\"training\", \"val\", \"test\"]\n",
    "):\n",
    "    print(f\"NLL on {df_name} set\")\n",
    "    for name, model in zip(names, models):\n",
    "        print(f\"{name}: {nll_dict[name]:.4f}\")\n",
    "    print(f\"-------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nll_wilcoxon_test(dists_val, Y_val, \"Validation\")\n",
    "nll_wilcoxon_test(dists_test, Y_test, \"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calculating CRPS\")\n",
    "grid = grid.squeeze()\n",
    "crps_train = {}\n",
    "crps_val = {}\n",
    "crps_test = {}\n",
    "\n",
    "\n",
    "for name, model in zip(names, models):\n",
    "    crps_train[name] = crps(Y_train, grid, cdfs_train[name])\n",
    "    crps_val[name] = crps(Y_val, grid, cdfs_val[name])\n",
    "    crps_test[name] = crps(Y_test, grid, cdfs_test[name])\n",
    "\n",
    "for crps_dict, df_name in zip(\n",
    "    [crps_train, crps_val, crps_test], [\"training\", \"val\", \"test\"]\n",
    "):\n",
    "    print(f\"CRPS on {df_name} set\")\n",
    "    for name, model in zip(names, models):\n",
    "        print(f\"{name}: {crps_dict[name].mean():.4f}\")\n",
    "    print(f\"------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crps_wilcoxon_test(cdfs_val, Y_val, grid, \"Validation\")\n",
    "crps_wilcoxon_test(cdfs_test, Y_test, grid, \"Validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_train = {}\n",
    "rmse_val = {}\n",
    "rmse_test = {}\n",
    "\n",
    "for name, model in zip(names, models):\n",
    "    means_train = dists_train[name].mean\n",
    "    means_val = dists_val[name].mean\n",
    "    means_test = dists_test[name].mean\n",
    "    rmse_train[name] = rmse(y_train, means_train)\n",
    "    rmse_val[name] = rmse(y_val, means_val)\n",
    "    rmse_test[name] = rmse(y_test, means_test)\n",
    "\n",
    "for rmse_dict, df_name in zip(\n",
    "    [rmse_train, rmse_val, rmse_test], [\"training\", \"validation\", \"test\"]\n",
    "):\n",
    "    print(f\"RMSE on {df_name} set\")\n",
    "    for name, model in zip(names, models):\n",
    "        print(f\"{name}: {rmse_dict[name].mean():.4f}\")\n",
    "    print(f\"-------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_wilcoxon_test(dists_val, Y_val, \"Validation\")\n",
    "rmse_wilcoxon_test(dists_test, Y_test, \"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 90 Quantile Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ql_90_train = {}\n",
    "ql_90_val = {}\n",
    "ql_90_test = {}\n",
    "\n",
    "for features, response, dataset_name, ql_dict in zip(\n",
    "    [X_train, X_val, X_test],\n",
    "    [y_train, y_val, y_test],\n",
    "    [\"Training\", \"Validation\", \"Test\"],\n",
    "    [ql_90_train, ql_90_val, ql_90_test],\n",
    "):\n",
    "    print(f\"{dataset_name} Dataset Quantile Loss(es)\")\n",
    "    for model, model_name in zip(models, names):\n",
    "        ql_dict[model_name] = (\n",
    "            quantile_losses_raw(  ## TODO from PL: ED to check - this originally didn't have \"raw\"\n",
    "                0.9,\n",
    "                model,\n",
    "                model_name,\n",
    "                features,\n",
    "                response,\n",
    "                max_iter=1000,\n",
    "                tolerance=1e-4,\n",
    "                l=torch.Tensor([0]),\n",
    "                u=torch.Tensor(\n",
    "                    [np.max(y_train) + 3 * (np.max(y_train) - np.min(y_train))]\n",
    "                ),\n",
    "            )\n",
    "        )\n",
    "    print(f\"----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = (glm, cann, mdn, ddr, drn)\n",
    "ql90_wilcoxon_test(models, X_val, Y_val, y_train, \"Validation\")\n",
    "ql90_wilcoxon_test(models, X_test, Y_test, y_train, \"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_table = generate_latex_table(\n",
    "    nlls_val,\n",
    "    crps_val,\n",
    "    rmse_val,\n",
    "    ql_90_val,\n",
    "    nlls_test,\n",
    "    crps_test,\n",
    "    rmse_test,\n",
    "    ql_90_test,\n",
    "    names,\n",
    "    label_txt=\"Evaluation Metrics\",\n",
    "    caption_txt=\"Model comparisons based on various evaluation metrics.\",\n",
    "    scaling_factor=0.95,\n",
    ")\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantile Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile_residuals_plots(quantile_points(cdfs_test, y_test, grid))\n",
    "plt.savefig(PLOT_DIR / \"Quantile Residuals Plot Synthetic.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_plot(cdfs_test, y_test, grid)\n",
    "plt.savefig(PLOT_DIR / \"Calibration Plot Synthetic.png\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sec 5.3.2: Interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigated Instance\n",
    "x_1 = 0.1\n",
    "x_2 = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local: Density Plot and Kernel SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise Explainer\n",
    "drn_explainer = DRNExplainer(\n",
    "    drn, glm, drn.cutpoints, x_train_raw, cat_features, all_categories, ct\n",
    ")\n",
    "\n",
    "# Plot adjustment factors\n",
    "drn_explainer.plot_adjustment_factors(\n",
    "    instance=pd.DataFrame(np.array([x_1, x_2]).reshape(1, 2), columns=[\"X_1\", \"X_2\"]),\n",
    "    num_interpolations=1000,\n",
    "    plot_adjustments_labels=False,\n",
    "    x_range=(0, 6),\n",
    "    synthetic_data=generate_synthetic_gamma_lognormal,\n",
    ")\n",
    "\n",
    "plt.savefig(PLOT_DIR / \"(0.1, 0.1) Density Plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drn_explainer = DRNExplainer(\n",
    "    drn,\n",
    "    glm,\n",
    "    drn.cutpoints,\n",
    "    x_train_raw,\n",
    "    cat_features,\n",
    "    all_categories,\n",
    "    column_transformer=ct,\n",
    ")\n",
    "\n",
    "# Plot DP adjustment SHAP for Mean Adjustment Explanation\n",
    "drn_explainer.plot_dp_adjustment_shap(\n",
    "    instance_raw=pd.DataFrame(\n",
    "        np.array([x_1, x_2]).reshape(1, 2), columns=[\"X_1\", \"X_2\"]\n",
    "    ),\n",
    "    method=\"Kernel\",\n",
    "    nsamples_background_fraction=0.5,\n",
    "    top_K_features=3,\n",
    "    labelling_gap=0.12,\n",
    "    dist_property=\"Mean\",\n",
    "    x_range=(2.14, 2.23),\n",
    "    y_range=(0.0, 0.75),\n",
    "    observation=True,\n",
    "    density_transparency=0.9,\n",
    "    adjustment=True,\n",
    "    shap_fontsize=15,\n",
    "    figsize=(7, 7),\n",
    "    plot_title=\"Mean Adjustment Explanation\",\n",
    "    synthetic_data=generate_synthetic_gamma_lognormal,\n",
    "    legend_loc=\"upper left\",\n",
    ")\n",
    "\n",
    "plt.savefig(PLOT_DIR / \"(0.1, 0.1) Mean Adjustment Plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drn_explainer = DRNExplainer(\n",
    "    drn,\n",
    "    glm,\n",
    "    drn.cutpoints,\n",
    "    x_train_raw,\n",
    "    cat_features,\n",
    "    all_categories,\n",
    "    column_transformer=ct,\n",
    ")\n",
    "\n",
    "drn_explainer.cdf_plot(\n",
    "    instance=pd.DataFrame(np.array([x_1, x_2]).reshape(1, 2), columns=[\"X_1\", \"X_2\"]),\n",
    "    method=\"Kernel\",\n",
    "    nsamples_background_fraction=0.005,\n",
    "    top_K_features=3,\n",
    "    labelling_gap=0.15,\n",
    "    dist_property=\"90% Quantile\",\n",
    "    quantile_bounds=(\n",
    "        torch.Tensor([drn.cutpoints[0]]),\n",
    "        torch.Tensor([drn.cutpoints[-1] * 2]),\n",
    "    ),\n",
    "    x_range=(3.4, 3.58),\n",
    "    y_range=(0.87, 0.93),\n",
    "    density_transparency=0.9,\n",
    "    adjustment=True,\n",
    "    shap_fontsize=15,\n",
    "    figsize=(7, 7),\n",
    "    plot_title=\"90% Quantile Adjustment Explanation\",\n",
    "    synthetic_data=generate_synthetic_gamma_lognormal,\n",
    ")\n",
    "\n",
    "plt.savefig(PLOT_DIR / \"(0.1, 0.1) Quantile Adjustment Plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drn_explainer = DRNExplainer(\n",
    "    drn,\n",
    "    glm,\n",
    "    drn.cutpoints,\n",
    "    x_train_raw,\n",
    "    cat_features,\n",
    "    all_categories,\n",
    "    column_transformer=ct,\n",
    ")\n",
    "\n",
    "# Plot CDF for 90% Quantile Explanation\n",
    "drn_explainer.cdf_plot(\n",
    "    instance=pd.DataFrame(np.array([x_1, x_2]).reshape(1, 2), columns=[\"X_1\", \"X_2\"]),\n",
    "    method=\"Kernel\",\n",
    "    nsamples_background_fraction=0.05,\n",
    "    top_K_features=3,\n",
    "    labelling_gap=0.16,\n",
    "    dist_property=\"90% Quantile\",\n",
    "    quantile_bounds=(\n",
    "        torch.Tensor([drn.cutpoints[0]]),\n",
    "        torch.Tensor([drn.cutpoints[-1] * 2]),\n",
    "    ),\n",
    "    x_range=(0, 8),\n",
    "    y_range=(0.0, 1.0),\n",
    "    density_transparency=0.9,\n",
    "    adjustment=False,\n",
    "    plot_baseline=False,\n",
    "    synthetic_data=generate_synthetic_gamma_lognormal,\n",
    "    shap_fontsize=15,\n",
    "    figsize=(7, 7),\n",
    "    plot_title=\"90% Quantile Explanation\",\n",
    ")\n",
    "\n",
    "plt.savefig(PLOT_DIR / \"(0.1, 0.1) Quantile Explanation Plot.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global: SHAP Dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise DRNExplainer\n",
    "drn_explainer = DRNExplainer(\n",
    "    drn, glm, drn.cutpoints, x_train_raw, cat_features, all_categories, ct\n",
    ")\n",
    "\n",
    "# Calculate Kernel SHAP values for the DRN model\n",
    "kernel_shap_drn = drn_explainer.kernel_shap(\n",
    "    explaining_data=x_test_raw,\n",
    "    distributional_property=\"Mean\",  # can change to 'XX% Quantile',\n",
    "    nsamples_background_fraction=0.5,\n",
    "    adjustment=True,\n",
    "    glm_output=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_shap_drn.global_importance_plot(num_features + cat_features, output=\"drn\")\n",
    "plt.savefig(PLOT_DIR / \"(Synthetic) SHAP Importance Mean.png\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_shap_drn.beeswarm_plot(num_features + cat_features, output=\"drn\")\n",
    "plt.savefig(PLOT_DIR / \"(Synthetic) SHAP Beeswarm Mean.png\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_shap_drn.shap_dependence_plot((\"X_1\", \"X_2\"), output=\"drn\")\n",
    "plt.savefig(PLOT_DIR / \"(Synthetic) SHAP Dependence Mean.png\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in names[1:]:\n",
    "    with open(MODEL_DIR / f\"{name.lower()}_hp.pkl\", \"rb\") as f:\n",
    "        res_hp = pickle.load(f)\n",
    "\n",
    "        with plt.rc_context(\n",
    "            {\n",
    "                \"xtick.labelsize\": \"x-small\",\n",
    "                \"ytick.labelsize\": \"x-small\",\n",
    "                \"axes.labelsize\": \"x-small\",\n",
    "                \"axes.titlesize\": \"x-small\",\n",
    "            }\n",
    "        ):\n",
    "            plot_objective(res_hp)\n",
    "            plt.savefig(PLOT_DIR / f\"{name.lower()}_hp.png\", bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
