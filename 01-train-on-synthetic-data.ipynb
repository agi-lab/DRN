{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "assert load_dotenv(find_dotenv(usecwd=False)), \"The .env file was not loaded.\"\n",
    "\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skopt\n",
    "import torch\n",
    "from drn import *\n",
    "from skopt.space import Categorical, Integer, Real\n",
    "\n",
    "from generate_synthetic_dataset import generate_synthetic_gamma_lognormal\n",
    "from hyperparameter_tuning_objectives import (\n",
    "    objective_cann,\n",
    "    objective_ddr,\n",
    "    objective_drn,\n",
    "    objective_mdn,\n",
    ")\n",
    "\n",
    "torch.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = Path(\"models/synth\")\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_opts = {\n",
    "    \"n_calls\": 125,\n",
    "    \"n_random_starts\": 25,\n",
    "    \"random_state\": 0,\n",
    "    \"verbose\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, target, means, dispersion = generate_synthetic_gamma_lognormal(20000)\n",
    "df = pd.concat([features, target], axis=1)\n",
    "df.to_csv(\"data/synth.csv\", index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    x_train,\n",
    "    x_val,\n",
    "    x_test,\n",
    "    y_train,\n",
    "    y_val,\n",
    "    y_test,\n",
    "    x_train_raw,\n",
    "    x_val_raw,\n",
    "    x_test_raw,\n",
    "    num_features,\n",
    "    cat_features,\n",
    "    all_categories,\n",
    "    ct,\n",
    ") = split_and_preprocess(\n",
    "    features, target, [\"X_1\", \"X_2\"], [], seed=42, num_standard=False\n",
    ")\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.Tensor(x_train.values)\n",
    "Y_train = torch.Tensor(y_train.values)\n",
    "X_val = torch.Tensor(x_val.values)\n",
    "Y_val = torch.Tensor(y_val.values)\n",
    "X_test = torch.Tensor(x_test.values)\n",
    "Y_test = torch.Tensor(y_test.values)\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train, Y_train)\n",
    "val_dataset = torch.utils.data.TensorDataset(X_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution = \"gamma\"  # distributional assumption for the GLM, CANN, MDN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(23)\n",
    "glm = GLM.from_statsmodels(X_train, Y_train, distribution=distribution)\n",
    "torch.save(glm, MODEL_DIR / \"glm.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_cann_synth = [\n",
    "    Integer(1, 4, name=\"num_hidden_layers\"),\n",
    "    Categorical([16, 32, 64, 128, 256, 512], name=\"hidden_size\"),\n",
    "    Real(0.0, 0.5, name=\"dropout_rate\"),\n",
    "    Real(0.0002, 0.01, name=\"lr\"),\n",
    "    Categorical([128, 256, 512], name=\"batch_size\"),\n",
    "]\n",
    "\n",
    "# Run Bayesian optimization\n",
    "res_cann_synth = skopt.gp_minimize(\n",
    "    lambda params: objective_cann(\n",
    "        params, X_train, Y_train, X_val, Y_val, train_dataset, val_dataset, glm, \"gamma\"\n",
    "    ),\n",
    "    space_cann_synth,\n",
    "    **hp_opts,\n",
    ")\n",
    "with open(MODEL_DIR / \"cann_hp.pkl\", \"wb\") as f:\n",
    "    res_cann_synth.specs[\"args\"].pop(\"func\")\n",
    "    pickle.dump(res_cann_synth, f)\n",
    "\n",
    "best_cann_params = res_cann_synth.x\n",
    "print(best_cann_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(23)\n",
    "cann = CANN(\n",
    "    glm,\n",
    "    num_hidden_layers=int(best_cann_params[0]),\n",
    "    hidden_size=int(best_cann_params[1]),\n",
    "    dropout_rate=best_cann_params[2],\n",
    ")\n",
    "train(\n",
    "    cann,\n",
    "    gaussian_deviance_loss if distribution == \"gaussian\" else gamma_deviance_loss,\n",
    "    train_dataset,\n",
    "    val_dataset,\n",
    "    epochs=2000,\n",
    "    lr=best_cann_params[-2],\n",
    "    patience=50,\n",
    "    batch_size=int(best_cann_params[-1]),\n",
    ")\n",
    "cann.update_dispersion(X_train, Y_train)\n",
    "torch.save(cann, MODEL_DIR / \"cann.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MDN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_mdn_synth = [\n",
    "    Integer(1, 4, name=\"num_hidden_layers\"),\n",
    "    Categorical([16, 32, 64, 128, 256, 512], name=\"hidden_size\"),\n",
    "    Real(0.0, 0.5, name=\"dropout_rate\"),\n",
    "    Real(0.0002, 0.01, name=\"lr\"),\n",
    "    Integer(2, 10, name=\"num_components\"),\n",
    "    Categorical([128, 256, 512], name=\"batch_size\"),\n",
    "]\n",
    "\n",
    "# Run Bayesian optimization\n",
    "res_mdn_synth = skopt.gp_minimize(\n",
    "    lambda params: objective_mdn(\n",
    "        params, X_train, Y_train, X_val, Y_val, train_dataset, val_dataset, \"gamma\"\n",
    "    ),\n",
    "    space_mdn_synth,\n",
    "    **hp_opts,\n",
    ")\n",
    "with open(MODEL_DIR / \"mdn_hp.pkl\", \"wb\") as f:\n",
    "    res_mdn_synth.specs[\"args\"].pop(\"func\")\n",
    "    pickle.dump(res_mdn_synth, f)\n",
    "best_mdn_params = res_mdn_synth.x\n",
    "print(best_mdn_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(23)\n",
    "mdn = MDN(\n",
    "    X_train.shape[1],\n",
    "    num_hidden_layers=int(best_mdn_params[0]),\n",
    "    hidden_size=int(best_mdn_params[1]),\n",
    "    dropout_rate=best_mdn_params[2],\n",
    "    num_components=int(best_mdn_params[-2]),\n",
    "    distribution=distribution,\n",
    ")\n",
    "train(\n",
    "    mdn,\n",
    "    gaussian_mdn_loss if distribution == \"gaussian\" else gamma_mdn_loss,\n",
    "    train_dataset,\n",
    "    val_dataset,\n",
    "    lr=best_mdn_params[3],\n",
    "    batch_size=int(best_mdn_params[-1]),\n",
    "    epochs=2000,\n",
    "    patience=50,\n",
    ")\n",
    "torch.save(mdn, MODEL_DIR / \"mdn.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_ddr_synth = [\n",
    "    Integer(1, 4, name=\"num_hidden_layers\"),\n",
    "    Categorical([16, 32, 64, 128, 256, 512], name=\"hidden_size\"),\n",
    "    Real(0.0, 0.5, name=\"dropout_rate\"),\n",
    "    Real(0.0002, 0.01, name=\"lr\"),\n",
    "    Categorical(np.linspace(0.01, 0.03, 9), name=\"proportion\"),\n",
    "    Categorical([128, 256, 512], name=\"batch_size\"),\n",
    "]\n",
    "\n",
    "# Run Bayesian optimization\n",
    "res_ddr_synth = skopt.gp_minimize(\n",
    "    lambda params: objective_ddr(\n",
    "        params, X_train, Y_train, X_val, Y_val, train_dataset, val_dataset\n",
    "    ),\n",
    "    space_ddr_synth,\n",
    "    **hp_opts,\n",
    ")\n",
    "with open(MODEL_DIR / \"ddr_hp.pkl\", \"wb\") as f:\n",
    "    res_ddr_synth.specs[\"args\"].pop(\"func\")\n",
    "    pickle.dump(res_ddr_synth, f)\n",
    "best_ddr_params = res_ddr_synth.x\n",
    "print(best_ddr_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(23)\n",
    "cutpoints_DDR = ddr_cutpoints(\n",
    "    c_0=y_train.min() * 1.05 if y_train.min() < 0 else 0.0,\n",
    "    c_K=y_train.max() * 1.05,\n",
    "    y=y_train,\n",
    "    p=best_ddr_params[-2],\n",
    ")\n",
    "ddr = DDR(\n",
    "    x_train.shape[1],\n",
    "    cutpoints_DDR,\n",
    "    num_hidden_layers=int(best_ddr_params[0]),\n",
    "    hidden_size=int(best_ddr_params[1]),\n",
    "    dropout_rate=best_ddr_params[2],\n",
    ")\n",
    "train(\n",
    "    ddr,\n",
    "    ddr_loss,\n",
    "    train_dataset,\n",
    "    val_dataset,\n",
    "    lr=best_ddr_params[3],\n",
    "    batch_size=int(best_ddr_params[-1]),\n",
    "    log_interval=1,\n",
    "    patience=30,\n",
    "    epochs=2000,\n",
    ")\n",
    "torch.save(ddr, MODEL_DIR / \"ddr.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DRN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_drn_synth = [\n",
    "    Integer(1, 4, name=\"num_hidden_layers\"),\n",
    "    Categorical([16, 32, 64, 128, 256, 512], name=\"hidden_size\"),\n",
    "    Real(0.0, 0.5, name=\"dropout_rate\"),\n",
    "    Real(0.0002, 0.01, name=\"lr\", prior=\"log-uniform\"),\n",
    "    Real(1e-5, 1e-1, name=\"kl_alpha\", prior=\"log-uniform\"),\n",
    "    Categorical([1e-5, 1e-4, 1e-3, 1e-2, 1e-1], name=\"mean_alpha\"),\n",
    "    Categorical([1e-3, 1e-2, 1e-1], name=\"dv_alpha\"),\n",
    "    Categorical([128, 256, 512], name=\"batch_size\"),\n",
    "    Categorical(np.linspace(0.02, 0.03, 5), name=\"proportion\"),\n",
    "    Categorical([1, 3, 5], name=\"min_obs\"),\n",
    "]\n",
    "\n",
    "# Run Bayesian optimization\n",
    "res_drn_synth = skopt.gp_minimize(\n",
    "    lambda params: objective_drn(\n",
    "        params,\n",
    "        criteria=\"CRPS\",\n",
    "        X_train=X_train,\n",
    "        Y_train=Y_train,\n",
    "        X_val=X_val,\n",
    "        Y_val=Y_val,\n",
    "        train_dataset=train_dataset,\n",
    "        val_dataset=val_dataset,\n",
    "        glm=glm,\n",
    "        kl_direction=\"forwards\",\n",
    "    ),\n",
    "    space_drn_synth,\n",
    "    **hp_opts,\n",
    ")\n",
    "with open(MODEL_DIR / \"drn_hp.pkl\", \"wb\") as f:\n",
    "    res_drn_synth.specs[\"args\"].pop(\"func\")\n",
    "    pickle.dump(res_drn_synth, f)\n",
    "best_drn_params = res_drn_synth.x\n",
    "print(best_drn_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(23)\n",
    "cutpoints_DRN = drn_cutpoints(\n",
    "    c_0=(y_train.min() * 1.05 if y_train.min() < 0 else 0.0),\n",
    "    c_K=y_train.max() * 1.05,\n",
    "    p=best_drn_params[-2],\n",
    "    y=y_train,\n",
    "    min_obs=int(best_drn_params[-1]),\n",
    ")\n",
    "drn = DRN(\n",
    "    num_features=X_train.shape[1],\n",
    "    cutpoints=cutpoints_DRN,\n",
    "    glm=glm,\n",
    "    hidden_size=int(best_drn_params[1]),\n",
    "    num_hidden_layers=int(best_drn_params[0]),\n",
    "    baseline_start=False,\n",
    "    dropout_rate=best_drn_params[2],\n",
    ")\n",
    "train(\n",
    "    model=drn,\n",
    "    criterion=lambda pred, y: drn_loss(\n",
    "        pred,\n",
    "        y,\n",
    "        kl_alpha=best_drn_params[4],\n",
    "        mean_alpha=best_drn_params[5],\n",
    "        dv_alpha=best_drn_params[6],\n",
    "        kl_direction=\"forwards\",\n",
    "    ),\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    batch_size=int(best_drn_params[7]),\n",
    "    epochs=2000,\n",
    "    patience=30,\n",
    "    lr=best_drn_params[3],\n",
    "    print_details=True,\n",
    "    log_interval=1,\n",
    ")\n",
    "torch.save(drn, MODEL_DIR / \"drn.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
