{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "import skopt\n",
    "from skopt.space import Integer, Real, Categorical\n",
    "from skopt.plots import plot_objective\n",
    "\n",
    "from drn import *\n",
    "\n",
    "from generate_synthetic_dataset import generate_synthetic_gamma_lognormal\n",
    "\n",
    "from hyperparameter_tuning_objectives import objective_cann, objective_ddr, objective_drn, objective_mdn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = Path(\"models/synth\")\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, target, means, dispersion = generate_synthetic_gamma_lognormal(20000)\n",
    "df = pd.concat([features, target], axis=1)\n",
    "df.to_csv(\"synth.csv\", index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, x_test, y_train, y_val, y_test,\\\n",
    "      x_train_raw, x_val_raw, x_test_raw,\\\n",
    "          num_features, cat_features,\\\n",
    "             all_categories, ct =\\\n",
    "                split_and_preprocess(features, target, ['X_1', 'X_2'], [], seed = 42, num_standard = False)\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.Tensor(x_train.values)\n",
    "Y_train = torch.Tensor(y_train.values)\n",
    "X_val = torch.Tensor(x_val.values)\n",
    "Y_val = torch.Tensor(y_val.values)\n",
    "X_test = torch.Tensor(x_test.values)\n",
    "Y_test = torch.Tensor(y_test.values)\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train, Y_train)\n",
    "val_dataset = torch.utils.data.TensorDataset(X_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution = \"gamma\" # distributional assumption for the GLM, CANN, MDN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(23)\n",
    "glm = GLM.from_statsmodels(X_train, Y_train, distribution=distribution)\n",
    "torch.save(glm, MODEL_DIR / \"glm.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_cann_synth = [\n",
    "    Integer(1, 4, name='num_hidden_layers'),\n",
    "    Categorical([16, 32, 64, 128, 256, 512], name='hidden_size'),\n",
    "    Real(0.0, 0.5, name='dropout_rate'),\n",
    "    Real(0.0002, 0.01, name='lr'),\n",
    "    Categorical([128, 256, 512], name='batch_size'),\n",
    "]\n",
    "\n",
    "# Run Bayesian optimization\n",
    "res_cann_synth = skopt.gp_minimize(\n",
    "    lambda params: objective_cann(params, X_train, Y_train, X_val, Y_val, train_dataset, val_dataset, glm, 'gamma'),\n",
    "    space_cann_synth,\n",
    "    n_calls=125,\n",
    "    n_random_starts=25,\n",
    "    random_state=0,\n",
    "    verbose=True\n",
    ")\n",
    "best_cann_params = res_cann_synth.x\n",
    "print(best_cann_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(23)\n",
    "cann = CANN(glm, num_hidden_layers=int(best_cann_params[0]), hidden_size=int(best_cann_params[1]),\n",
    "         dropout_rate = best_cann_params[2])\n",
    "train(\n",
    "    cann,\n",
    "    gaussian_deviance_loss if distribution == \"gaussian\" else gamma_deviance_loss,\n",
    "    train_dataset,\n",
    "    val_dataset,\n",
    "    epochs=2000,\n",
    "    lr=best_cann_params[-2],\n",
    "    patience=50,\n",
    "    batch_size=int(best_cann_params[-1]),\n",
    ")\n",
    "cann.update_dispersion(X_train, Y_train)\n",
    "torch.save(cann, MODEL_DIR / \"cann.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MDN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_mdn_synth = [\n",
    "    Integer(1, 4, name='num_hidden_layers'),\n",
    "    Categorical([16, 32, 64, 128, 256, 512], name='hidden_size'),\n",
    "    Real(0.0, 0.5, name='dropout_rate'),\n",
    "    Real(0.0002, 0.01, name='lr'),\n",
    "    Integer(2, 10, name='num_components'),\n",
    "    Categorical([128, 256, 512], name='batch_size'),\n",
    "]\n",
    "\n",
    "# Run Bayesian optimization\n",
    "res_mdn_synth = skopt.gp_minimize(\n",
    "    lambda params: objective_mdn(params,\n",
    "                                X_train,\n",
    "                                Y_train,\n",
    "                                X_val, \n",
    "                                Y_val, \n",
    "                                train_dataset, \n",
    "                                val_dataset, \n",
    "                                'gamma'),\n",
    "    space_mdn_synth,\n",
    "    n_calls=125,\n",
    "    n_random_starts=25,\n",
    "    random_state=0,\n",
    "    verbose=True\n",
    ")\n",
    "best_mdn_params = res_mdn_synth.x\n",
    "print(best_mdn_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(23)\n",
    "mdn = MDN(\n",
    "        X_train.shape[1],\n",
    "        num_hidden_layers=int(best_mdn_params[0]),\n",
    "        hidden_size=int(best_mdn_params[1]),\n",
    "        dropout_rate = best_mdn_params[2],\\\n",
    "        num_components=int(best_mdn_params[-2]),\n",
    "        distribution= distribution)\n",
    "train(\n",
    "    mdn,\n",
    "    gaussian_mdn_loss if distribution == \"gaussian\" else gamma_mdn_loss,\n",
    "    train_dataset,\n",
    "    val_dataset,\n",
    "    lr=best_mdn_params[3],\n",
    "    batch_size=int(best_mdn_params[-1]),\n",
    "    epochs=2000,\n",
    "    patience=50,\n",
    ")\n",
    "torch.save(mdn, MODEL_DIR / \"mdn.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_ddr_synth = [\n",
    "    Integer(1, 4, name='num_hidden_layers'),\n",
    "    Categorical([16, 32, 64, 128, 256, 512], name='hidden_size'),\n",
    "    Real(0.0, 0.5, name='dropout_rate'),\n",
    "    Real(0.0002, 0.01, name='lr'),\n",
    "    Categorical(np.linspace(0.01, 0.03, 9), name='proportion'),\n",
    "    Categorical([128, 256, 512], name='batch_size'),\n",
    "]\n",
    "\n",
    "# Run Bayesian optimization\n",
    "res_ddr_synth = skopt.gp_minimize(\n",
    "    lambda params: objective_ddr(params, X_train, Y_train, X_val, Y_val, train_dataset, val_dataset),\n",
    "    space_ddr_synth,\n",
    "    n_calls=125,\n",
    "    n_random_starts=25,\n",
    "    random_state=0,\n",
    "    verbose=True\n",
    ")\n",
    "best_ddr_params = res_ddr_synth.x\n",
    "print(best_ddr_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(23)\n",
    "cutpoints_DDR = ddr_cutpoints(c_0 = np.min(y_train) * 1.05 if np.min(y_train) < 0 else 0.0,\n",
    "                              c_K = np.max(y_train) * 1.05, \n",
    "                              y = y_train,\n",
    "                              p = best_ddr_params[-2])\n",
    "ddr = DDR(x_train.shape[1], cutpoints_DDR , num_hidden_layers=int(best_ddr_params[0]),\n",
    "                     hidden_size=int(best_ddr_params[1]), dropout_rate = best_ddr_params[2])\n",
    "train(\n",
    "    ddr,\n",
    "    ddr_loss,\n",
    "    train_dataset,\n",
    "    val_dataset, \n",
    "    lr=best_ddr_params[3],\n",
    "    batch_size=int(best_ddr_params[-1]),\n",
    "    log_interval=1,\n",
    "    patience=30,\n",
    "    epochs=2000,\n",
    ")\n",
    "torch.save(ddr, MODEL_DIR / \"ddr.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DRN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_drn_synth = [\n",
    "    Integer(1, 4, name='num_hidden_layers'),\n",
    "    Categorical([16, 32, 64, 128, 256, 512], name='hidden_size'),\n",
    "    Real(0.0, 0.5, name='dropout_rate'),\n",
    "    Real(0.0002, 0.01, name='lr', prior = 'log-uniform'),\n",
    "    Real(1e-5, 1e-1, name='kl_alpha', prior = 'log-uniform'),\n",
    "    Categorical([1e-5, 1e-4, 1e-3, 1e-2, 1e-1], name='mean_alpha'),\n",
    "    Categorical([1e-3, 1e-2, 1e-1], name='dv_alpha'),\n",
    "    Categorical([128, 256, 512], name='batch_size'),\n",
    "    Categorical(np.linspace(0.02, 0.03, 5), name='proportion'),\n",
    "    Categorical([1, 3, 5], name='min_obs'),\n",
    "]\n",
    "\n",
    "# Run Bayesian optimization\n",
    "res_drn_synth = skopt.gp_minimize(\n",
    "    lambda params: objective_drn(params, criteria = 'CRPS', \n",
    "                                X_train=X_train,\n",
    "                                Y_train=Y_train,\n",
    "                                X_val=X_val,\n",
    "                                Y_val=Y_val,\n",
    "                                train_dataset=train_dataset,\n",
    "                                val_dataset=val_dataset,\n",
    "                                glm = glm,\n",
    "                                kl_direction = 'forwards'),\n",
    "    space_drn_synth,\n",
    "    n_calls=125,\n",
    "    n_random_starts=25,\n",
    "    random_state=0,\n",
    "    verbose=True\n",
    ")\n",
    "best_drn_params = res_drn_synth.x\n",
    "print(best_drn_params)\n",
    "\n",
    "# If we wish,we can generate the following 'correlation' plot,\n",
    "# loss function values vs. hyperparameters \n",
    "with plt.rc_context(\n",
    "                {'xtick.labelsize': 'x-small', \n",
    "                 'ytick.labelsize': 'x-small',\n",
    "                 'axes.labelsize': 'x-small',\n",
    "                 'axes.titlesize': 'x-small'}):\n",
    "    plot_objective(res_drn_synth)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(23)\n",
    "cutpoints_DRN = drn_cutpoints(\n",
    "    c_0=np.min(Y_train.detach().numpy()) * 1.05\n",
    "        if np.min(Y_train.detach().numpy()) < 0 else 0.0,\n",
    "    c_K=np.max(Y_train.detach().numpy()) * 1.05,\n",
    "    p=best_drn_params[-2],\n",
    "    y=Y_train.detach().numpy(),\n",
    "    min_obs=int(best_drn_params[-1])\n",
    ")\n",
    "drn = DRN(\n",
    "    num_features=X_train.shape[1],\n",
    "    cutpoints=cutpoints_DRN,\n",
    "    glm=glm,\n",
    "    hidden_size=int(best_drn_params[1]),\n",
    "    num_hidden_layers=int(best_drn_params[0]),\n",
    "    baseline_start=False,\n",
    "    dropout_rate=best_drn_params[2]\n",
    ")\n",
    "train(\n",
    "    model=drn,\n",
    "    criterion=lambda pred, y: drn_loss(\n",
    "        pred, y,\n",
    "        kl_alpha=best_drn_params[4],\n",
    "        mean_alpha=best_drn_params[5],\n",
    "        dv_alpha=best_drn_params[6],\n",
    "        kl_direction='forwards'\n",
    "    ),\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    batch_size=int(best_drn_params[7]),\n",
    "    epochs=2000,\n",
    "    patience=30,\n",
    "    lr=best_drn_params[3],\n",
    "    print_details=True,\n",
    "    log_interval=1,\n",
    ")\n",
    "torch.save(drn, MODEL_DIR / \"drn.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
